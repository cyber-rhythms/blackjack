{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigations into the game of Blackjack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this article is to investigate and explore some key results in the well-studied game of Blackjack. The aim is to subject the claims that have been made by those in the Blackjack community, and the academic results that have been published, to a degree of critical scrutiny. We will motivate our exposition using non-technical questions which a reasonable person in a casino might ask themselves, and will primarily use tools in Monte Carlo simulation, probability, statistics and to a milder extent, combinatorics, to explore the limits of claims that have been made and figures that have been published. \n",
    "\n",
    "No acquaintance with the game of Blackjack is assumed, although a very mild familiarity will certainly be helpful to visualise and appreciate some of the issues. The aim is to clarify the issues to someone who is not well acquainted with its language. A similar position is taken on the technical arguments made - effort will be made to clarify their premises and implications to a non-technical audience. In particular, we justify our reasons for adopting a particular method or argument, together with our thoughts on why we deemed it was appropriate to a particular aspect of the problem. Where appropriate, we provide comment on the historical contexts from which a methodology emerged, and their relation to other fields of research.  Where there are approaches which after investigation turned out to be less fruitful than we had expected, we report them and we qualify why they turned out to be less fruitful than originall expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Outline of rules and terminology, benchmark variation.\n",
    "* Questions and objectives\n",
    "* Reported statistics on the casino's advantage - the House \"Edge\".\n",
    "* Player's optimal strategies for decision and betting.\n",
    "    * Naive strategy (optional, but good for baseline)\n",
    "    * Evolution of Basic Strategy\n",
    "        * Brief review (Baldwin, Manson).\n",
    "        * Illustrate the principle simply\n",
    "        * List the recursive calculations given by Wizard of Odds.\n",
    "        * Discuss limitations of the applicability of Basic Strategy (sampling with replacement).\n",
    "    * HI-LO Card Counting\n",
    "        * Brief review of cluster work in the 60s (Thorp, Wong, Griffin).\n",
    "        * Illustrate the core principle simply.\n",
    "        * Show how these principles were derived.\n",
    "    * Optimal betting under Kelly Criterion\n",
    "        * Busting the myth of progressive betting/martingale betting strategy.\n",
    "        * Brief review of the cluster of work in the 70s (Shannon, Kelly, Breiman, Thorp)\n",
    "        * Illustrate the principle.\n",
    "* Methodology\n",
    "* Areas not considered        \n",
    "* Preliminary validations - House \"Edge\", Basic Strategy, Card Counting.\n",
    "* Implememtation details\n",
    "* Results\n",
    "* Discussion\n",
    "    * Randomness, pseudorandomness\n",
    "    * Pseudo-random number generators and their role in Monte Carlo simulations.\n",
    "    * Casino counter-measures - an outlook\n",
    "* Further work\n",
    "* Footnotes\n",
    "* References\n",
    "* Figures\n",
    "* Appendices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Questions and objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original questions and objectives we would like to explore are the following. As our findings progressed, some of these had to be refined as it turned out that they could not be legitimately answered. \n",
    "\n",
    "Rather than specifying a literature review at the beginning, we use a series of questions to motivate a narrative trajectory through the relevant literature. In this way we can get a chronological understanding of how the current state of knowledge on this game developed in parallel with theoretical developments.\n",
    "\n",
    "1a) Do there exist any \"optimal strategies\" in Blackjack that prescribe what a player should do for the situations encountered, and also on the amount they should wager?\n",
    "\n",
    "1b) If so, in what sense are they are \"optimal\", and what assumptions are being used?\n",
    "\n",
    "1) For a player starting with a fixed amount of capital, what is the \"average\" amount of capital she is likely to end up with if she plays a naive strategy, and a \"basic strategy\", and with fixed betting behaviour?\n",
    "\n",
    "2) Similarly, what is the \"average\" amount of capital she will end up with if she opts for an \"advantage strategy\", such as HI-LO card card counting with variable betting behaviour?\n",
    "\n",
    "3) Related, but not the same, how much is a casino expected to retain, or to lose, if they offer Blackjack on their portfolios?\n",
    "\n",
    "3) What real-world insights, if any, can we gain through the proper application of applied mathematical methods, such as time-series analysis?\n",
    "\n",
    "3) Can contemporary applied mathematics developed over the last century or so supplement our understanding, which could not be gained without their use?\n",
    "\n",
    "3a) What are the properties of the player's capital stock as a function of time, under the different betting and play strategies outlined above?\n",
    "\n",
    "3c) Are there any systematic, observed, statistical regularities when different betting and play strategies are used?\n",
    "\n",
    "3d) What are the properties of an ensemble of time series of the player's capital stock as a function time, under the different betting and play strategies outlined above?\n",
    "\n",
    "3e) What kinds of stochastic processes, if any, would best characterise the evolution of player capital stock as a function of time?\n",
    "\n",
    "Time permitting and main questions*:\n",
    "\n",
    "4) What, if any role, could machine learning (in particular reinforcement learning, deep learning or deep reinforcement learning) play?\n",
    "\n",
    "5) Can machine learning methods reproduce an advantage strategy?\n",
    "\n",
    "6) A final broader question. What insights,if any, can an understanding of *mechanism* underlying a data generating process yield that cannot be gained through solely data-driven methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo simulation - some preliminaries. \n",
    "\n",
    "As a preliminary starting point to answer these questions, and having no knowledge of the complexities of some of the issues involved, our first port-of-call was to use the object-oriented progamming language, Python, to develop a simulator that could mimic the mechanics of the game. The simulator needed to fulfil the following criteria, some of which are are less trivial than others:-\n",
    "\n",
    "1) It must implement the variant of the rules that we have selected correctly.\n",
    "\n",
    "2) It must retain a degree of \"casino realism\".\n",
    "\n",
    "3) It must be able to correctly encode the behaviours and strategies that we outlined above and implement these correctly.\n",
    "\n",
    "4) It must be efficient enough to be able to generate enough results for us to investigate the questions we have outlined.\n",
    "\n",
    "5) We must have confidence that the results produced by our simulator are accurate, reliable, and valid.\n",
    "\n",
    "Questions 1. to questions 4. concerns the functionality of the simulator, and is significant for analysis only to the extent to which it works appropriately. These are covered in greater depth under the \"Implementation\" and \"Validation\" sections.\n",
    "\n",
    "Critical assessment of these questions are not as important for analysis as say question 5. Essentially, we are using the simulator as a substitute for a natural experiment. Epistemologically, it is perhaps best to think of it as a \"quasi-experiment\". There are two facets of simulation we want to emphasise here, namely its difference from a natural experiment, and some of the conditions that must be satisfied for us to rely on its output *as if it were a natural experiment*.\n",
    "\n",
    "The first difference between a simulated quasi-experiment and a randomised trial is the lack of a physical process. If we wanted to use randomised trials to investigate how the player's capital stock would evolve over time under:\n",
    "\n",
    "i) A naive strategy with fixed betting behaviour\n",
    "\n",
    "ii) A \"basic strategy\" with fixed betting behaviour\n",
    "\n",
    "iii) An advantage strategy such as \"HI-LO card counting\" under variable betting behaviour\n",
    "\n",
    "We would then need to find a willing respondent who would have to play a large number of rounds of Blackjack under each of the strategies i), ii) and iii), and for each of those strategies, under identical conditions. We would also require the player to execute the strategies with perfect precision. Only then we would be able to ascribe changes in player strategy and betting behaviour to changes in the evolution of their capital stock.\n",
    "\n",
    "Using a simulation, all of this could be executed electronically, and we focus on two significant mechanisms in which a substitution of a physical process for a virtual process needs to be exercised with caution:-\n",
    "\n",
    "1) The mechanism by which the rules of the game are executed. Encompassing the player betting, to the receipt of cards from the shoe, the execution of player decisions, the execution of the rules governing dealer behaviour, the resolution of the hand, paying out or taking bets, and finally, the act of shuffling the cards. The entire mechanism, with the exception of the shuffling, are covered by the desirable properties 1) - 4) of a simulator.\n",
    "\n",
    "2) The shuffling mechanism. This is less trivial and involves some nuances in randomness and pseudo-randomness from a computational point of view, which we defer to the discussion section. For now, it suffices to say that as we are substituting the physical act of card shuffling by hand, or by a machine, with using a virtual source of (pseudo)-randomness to mimic that process, we need to have confidence that this substitution will not affect the degree to which we can rely on the simulation output, as if it were a randomised trial.\n",
    "\n",
    "Provided all the above concerns and reservations are satisfactorily addressed, the use of simulation can serve as a virtual substitute to a randomised trial. \n",
    "\n",
    "The primary benefit use of simulation confers is that output results can be generated at a faster rate and at a greater volume than would otherwise be possible - it would not be possible to play 1 billion hands of Blackjack in the space of an hour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo Simulation\n",
    "\n",
    "It is by no coincidence that a certain class of simulation methods are known as Monte Carlo methods, aptly named by one of its progenitors, Nicholas Metropolis, after a famous casino in France. Its other progenitor, Stanislaw Ulam, elucidated on the connection between card games and simulation here:\n",
    "\n",
    "\"The first thoughts and attempts I made to practice [the Monte Carlo method] were suggested by a question which occurred to me in 1946 as I was convalescing from an illness and playing solitaires. The question was what are the chances that a Canfield solitaire laid out with 52 cards will come out successfully? After spending a lot of time trying to estimate them by *pure combinatorial calculations*, I wondered whether a more practical method than \"abstract thinking\" might not be to lay it out say one hundred times and simply observe and count the number of successful plays. This was already possible to envisage with the beginning of the new era of fast computers, and I immediately thought of problems of neutron diffusion and other questions of mathematical physoics, and more generally how to change processes described by certain differential equations into an equivalent form interpretable as a succession of random operations...[in 1946, I] described the idea to John von Neumann and we began to plan actual calculations.\" [REF]\n",
    "\n",
    "Together with its other progenitor, John von Neumann, one of whose many contributions the responsibility for the design and implementation of the earlier digital computer, the ENIAC, this trio deserve acknowledgement for their contributions to the methods of simulation that are arguably a defining feature of late 20th and early 21st Century scientific method. The applications of simulation are too numerous to list here, but some notable ones would be in nuclear physics, for exploring neutron chain reactions in explosive fission weapons, under the codename of the Manhattan Project; in contemporary meteorology; and lastly by the Blackjack community in the 1960s.\n",
    "\n",
    "It is necessary to briefly discuss the rationale and limitations of using simulations as a general strategy, and why we felt it was necessary in light of our limited understanding of the problem structure. \n",
    "\n",
    "* Metropolis, Ulam (1949): Study of certain kinds of physical problem and continuum vs kinetic theories. Analogous sitation with problems of combinatorial analysis and of the theory of probabilities. Calculate the probability of a successful outcome of solitaire analytically -> totally intractable. LLN and asymptotic theorems will not shed light on qualitative questions concerning such proababilities. Obviously, teh practical procedures is to produce a large number of examples of any given game and then toe examine the relative proportion of successes. The \"solitaire\" is meant here merely as an illustration of the whole class of combinatorial problems occurring in both pure mathematics and the applied sciences. We can see at once that the estimate will never be confined within given limits with certainty, but only - if the number of trials is great - with great probability. Even to establish this much we must have recourse to the laws of large numbers and other results of the theory of probabilities.\n",
    "\n",
    "* Metropolis, Ulam (1949): Evaluating the volume of a region in, say, a twenty-dimensional space...The prcoedure based on the definition of a volume or the definition of an integral i.e. the subdivision of the whole unit cube, for example, each cordinate x_1 into ten parts, leads to an examination of 10^20 points in the unit cube. It is obviously impossible to count all of them. Here again the more sensible approach would be to take say 10^4 points at random from this *ensemble* and examine those only i.e. we should count how many of the selected points satisfy all the given inequalities. It follows form the simple applciation of ergodic theorems that the estimates should be, with great probability, valid within a few per cent.\n",
    "\n",
    "\n",
    "- Trim this down, but my take is the idea of using simulation as a means of generating an (artificial) ensemble where in practice there would be no ensemble, but only a trajectory. This simulated ensemble is a sample of the entire population ensemble, which is computationally not tractable to evaluate.\n",
    "\n",
    "* Metropolis, Ulam (1949): Flow of a phase space and neutron diffusion. The mathematical description is the study of a flow which consists of *a mixture of deterministic and stochastic processes*. It requires its own law of large numbers and asymptotic theorems, the study of which has only begun. The computational procedure looks in practice as follows: we imagine that we have an *ensemble of particles* each represented by a set of numbers. These numbers specify the time, components of position and velocity vectors, also an index identifying the nature of the particle. With each othese sets of numbers, random processes are initiated which lead to the detemination of a new set of values. There exists indeed a *set of probability distribtuons* for the new values of the parameters after a specified time interval $\\Delta{t}$. Imagine that we draw at random and *independently* (their emphasis), values from a prepared collection possessing such distributions. Here a distinction must be made between theose parameters which we believe vary indepdently of each other, and those values which are strictly determined by the values of other parameters...By considering a large number of particles with their corresponding sets of parameters we obtain in this fashion another collection of particles and a new class of sets of values of their parameters. The hope is, of course, that in this manner *we obtain a good sample of the distributions at the time $t + \\Delta{t}$*. This procedure is repeated as many times as required for the duration of the real process or else, in problems where we believe a stationary distribution exists, until our \"experimental distributions do not show significant changes form one step to the next\". The essential feature of the process is we avoid dealing wiht multiple integrations or multiplcations of the probability matrices, but instead sample single chains of events. \n",
    "\n",
    "\n",
    "* Metropolis, Ulam (1949), von Neumann (1956) - PRNGS.\n",
    "\n",
    "\n",
    "* Ulam (1950) - \"The combinatorial complexity alone, present in such diverse problems as hydrodynamics, the theory of cosmic rays, the theory of nuclear reaction in heterogeneuous media, is very great.\"\n",
    "\n",
    "* Ulam (1950) - \"Systems involving, so to say, and intermediate situation have been becoming, in more recent years, more and more important in both theory and practice. A mechanical problem of a system of N bodies, with forces acting between them (we think of N as having a value like say, 10 or 20) would present an example of this kind. Similarly, one can think of a continuum, say a fluid subject to given forces in which, however, we are interested in the values of N quantities describing the whole continuum of the fluid. Neither of the two extreme approaches which we mentioned is very practical in such cases. It will be impractical to try to solve exactly the deterministic equations. The purely statistical study of the system, in the spirit of thermodynamics, will not be detailed enough. The approach should be rather a combination of the two extreme points of view, the classical one of following step by step in time and space the action of differential and integral operators and the stochastic method of averaging over whole classes of initial conditions, relations, and interactions. We propose a way to combine the deterministic and probability method by some general mathematical algorithms.\"\n",
    "\n",
    "* Ulam (1950) - \"One should remember that the distinction between a probabilistic and deterministic point of view lies often only in the interpretation nad not in the mathematical treatment itself. A well-known example of this is the comparison of two problems (1) Borel's law of large numbers for the sequence of the throws of a coin and (2) a simple version of the ergodic theorem of Birkhoff: if one applies this ergodic tehorem to a varey special sitatuion, namely the system of real numbers in a binary expansion, the transformation T of this set on tiself being a shift of the binary development by 1, one will realise that theorems of Borel and Brikhoff assert in this case the same thing (indepdently noticed by Doob, E Hopf, Khintchine). In this case a formulation of the theory of probability and a deterministic one of iterating a well-defined transfomration are mathematicall equivalent.\n",
    "\n",
    "* In simple situations, one might combine the two points of view: the one of probabilty theories, the other of iterating given transformations as follows. Givcen a space $E$,; given also are several measure preserving transformations $T_1, T_2,...,T_n$. We start with a point $p$ and apply to it in turn at random the given transformations. Assume for simplicity that at each time each of the N given transformations has an equal chance = $1/N$ of being applied. It was proved by von Neumann and the author that the ergodic theorem still holds in the following version: for almost every sequence of choices of these transofmartions and for almost every point p the ergodic limit will exist. The proof consists in the use of the ergodic theorem of Birkhoff in a suitably defined space embodying, as it wer the sapce of all chocies of the given transofmration over the sapce E. The question of metric transivity of a transformation i.e. the question whether the limit in time is equal to the space average, can be similarly generalised from the iteration of a given transformation to teh situation dealt with above; that is the behaviour of a sequence of points obtained by using several transfomrations at random. One can again show, similarly to teh case of one transformation that metric transivity obtains in verty general cases.\"\n",
    "\n",
    "\n",
    "* Ulam (1950): \"Statistical models, that is, the random processes equivalent to the deterministic transformations, are obvious in the case of physical proceses described by differential diffusion equations or by intergral differential equations of the Boltzmann type. These processes are of course, *\"random walks\"*. One finds in extensive literature dealing with stochastic porcesses the foundations for construction and study of such models, at leas for simple problkmes of the above type. It is known that limiting distribtuions resulting from ushc processes obey certain partial differential equations. Our aim is to invert the usual procedure. Given a partial differential equation, we construct models of suitable games and obtain distribtuions or solutions of the corresponding equations by playing these games i.e. by experiment. As an illustration consider the problem of description of large cosmic ray showers. It can be schematised as follows:\n",
    "\n",
    "* An incoming particle produces with certain probabilities new particles; each of these new particles which are of several kinds,is moreover, characterised by additional indices givning its momenta and eenrgies. These particles can further multiply into new ones until the nergies in the alst generation fall under certain given limits. The problem is first: to predict, from the given probabilities of reactions, the statistical properties of the shower; secondly a more difficult one, the inverse problem, where the elementary probabilties of transofmarion are not known byt statistics of the showers are available, to estimate these probabilities from the proabibilities of the shpwer. Mathematically the probme is described by by a system of ordinary differnial equations or by a matrix of rreansition probabiolites. \n",
    "\n",
    "* A way to get the necessary statistics may be of course to produce a large number of these shpwers by playing a game of chance wirth assumed probabilities and examine the resulting distributions statistically. This may be more economical than teh actual computation of the pwoers of teh matrices descirbing the transition and transutation of probabilties. The multiplication of matrices corresponds to evaluation of conteingencies at each stage, whereas by playing the game of chance we select at each stage only *one* of the alternatives. \n",
    "\n",
    "- Again, I have a feeling this kind of thinking can add to the discussion in context of the combinatorial complexity of Blackjack. And computational compelxity. And the sense of ther eexisting a \"branching process\" whihc would be intractable to compute. Read through thsi again and jot some thoughts down.\n",
    "\n",
    "- There exists the germs of an analogy here. \n",
    "\n",
    "* What particular aspects of the problem structure suggests that Monte Carlo is a good route to go down?\n",
    "* How is it a Monte Carlo method vs just simulation. Does it meet the criteria?\n",
    "* What about the Blackjack problem structure warrants the use of Monte Carlo simulatiuon.\n",
    "* Any insights made bu the authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reported statistics on the casino's advantage -  the House \"Edge\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*\"How much is a player expected to win or lose, and under what conditions?\" - what the Gambling Commission and casinos report.\n",
    "\n",
    "In the United Kingdom, casinos and commercial gambling are regulated by the Gambling Commission under the Gambling Act 2005. The Gambling Commission is an executive non-deparmental public body that is responsible for the regulating gambling and supervising gaming law in Great Britain.\n",
    "\n",
    "Casinos in the UK are generally mandated to provide \"player information on the rules of each type of casino game on offer and a players' guide to the house edge (giving the odds offered) must be displayed in each casino\" [REF].\n",
    "\n",
    "We decided the first step towards clarifying the answer to this question was to search for and collate official, credible sources of information on the House \"Edge\". To understand why we imposed this criterion, a Google search of \"house edge uk casino\" reveals a plethora of websites; each proffering estimates of the House \"Edge\" for Blackjack in a ball-park range of 0.1% - 12%. The majority of these websites state their figures quite confidently, but suffer from a lack of rigour and clarity - they do not report any details on how these figures were calculated, and the particular rule variant of Blackjack for which these figures apply. With some exceptions, many of the websites appear to be gaming industry affiliated, and so the weighting we give to these figures is very low - they may have some subsidiary use as an approximate estimate, but the lack of details on their calculation means that we cannot subject them to critical scrutiny - they may as well be figures plucked out of thin air. \n",
    "\n",
    "Credibility considerations in mind, the only source of \"official information\" on the House \"Edge\" for UK casinos in general that we found was at the website ukcasinotablegames.info. The website belongs to the casino trade-body, the Casino Games Review Group, and is linked by the UK Gambling Commission, the government non-departmental public body responsible for regulating gambling and supervising gaming law in the United Kingdom. For these reasons, we felt that it served as a reliable first baseline approximation to gauge the House \"Edge\". An excerpt is below, with our emphasis in italics:-\n",
    "\n",
    "\"Casino games, such as Roulette, *Blackjack*, Punto Banco etc. are bankers' games and, as such, are games of \"unequal chance\". The nature and structure of these games therefore gives an advantage to the casino (the House).\n",
    "\n",
    "This is called the \"House Edge\", and it gives a measure of the percentage that a casino would *expect to retain on average, from each hand or spin, given normal patterns of play*. In very simple terms it largely works in two ways:-\n",
    "\n",
    "* In games such as Blackjack, for example, the Dealer wins all bets from losing players, even if their own hand is also bust. This is because the Dealer \"holds the bank\". By contrast, a player will only win if their hand beats that of the Dealer.\n",
    "\n",
    "* In other bankers' games, like Roulette, the \"Edge\" is achieved by the casino paying slightly less than the \"true\" odds for a particular bet. For example, the true odds for a single Roulette number to win are 36 to 1, since there are 37 compartments on the wheel. However, winning bets are actually paid at 35 to 1.\n",
    "\n",
    "The \"Edge\" is a universally accepted feature of International casino gmaing and, in fact, is often less in the UK than that applied in many other countries. Nonetheless, the casino industry and the UK Gambling Commission both support a policy for openness and clarity towards those participating in UK gaming, so this website gives details of the House \"Edge\" percentage for all games displayed on the individual rules pages.\n",
    "\n",
    "Only the basic \"House Edge\" percentages have been illustrated. However, please note that these figures *will vary* in certain playing conditions.\n",
    "\n",
    "In Blackjack, for example, the House \"Edge\" *can fluctuate widely* (both for and against the house) *depending on the techniques applied by individual players*...The edge may also differ depending on the odds payable at individual casinos. \n",
    "\n",
    "Players should always check the House Edge information applicable at the individual casino at which they wish to play. This can be found either in House Edge leaflets or other means of displaying the information, which is a requirement at all casino premises.\"\n",
    "\n",
    "The reported statistics on the House \"Edge\" in the same website gives the following calculations:"
   ]
  },
  {
   "attachments": {
    "Untitled.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Untitled.png](attachment:Untitled.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the interests of clarity, it's necessary to outline some of the caveats that must be borne in mind when looking at these figures, and what it means for their validation. Let's begin by looking at some of the phrases we have italicised above.\n",
    "\n",
    "* \"a measure of the percentage that a casino would expect to retain on average, from each hand or spin, given normal patterns of play.\"\n",
    "\n",
    "The House \"Edge\" is a *statistical average*. Statistical averages are *theoretical constructs* which often need to be treated with caution, and we will give an example after we have dealt with the crux of the matter. It has a particular technical sense in the language of statistics, probability, and decision theory as the *expected value of a player's wager for each hand*.\n",
    "\n",
    "To illustrate this in context of the first line of the table, in which the House \"Edge\" is quoted as \"-0.51%\", it means that when 4 decks are being used, for every £10 that the player wagers in a hand, she will expect to incur a loss of £0.05 (rounding down from £0.051) and thereby finish the hand with £9.95, *on average* and *under a precise hypothetical set of conditions*.\n",
    "\n",
    "What is the significance of our qualification that this is \"on average\" and \"under a precise hypothetical set of conditions\"?\n",
    "\n",
    "*On average* here has a very specific technical meaning which can be overlooked by those who routinely see these kinds of calculations. It means that if a player were to enter a casino and played a progressively larger and larger number of hands of Blackjack, record how much they won and lost in each hand as an overall total, then divide that total by the number of hands they played, the loss they would find they incurred per hand would get closer and closer to £0.05. However, this must be treated with the essential reservation that the result holds under a *hypothetical set of conditions*, conditions which we will clarify once the calculation has been scrutinised. \n",
    "\n",
    "To illustrate how the technical notion of a *statistical average* could be misinterpreted, the quoted House \"Edge\" does not refer to the amount that the \"average casino\" in the UK would expect to retain from each hand, nor does it refer to the amount that the \"average player\" in the UK would expect to retain from each hand. [FOOTNOTE]\n",
    "\n",
    "* \"The edge may also differ depending on the odds payable at individual casinos.\"\n",
    "\n",
    "As has been covered earlier, the House \"Edge\" is a statistical average of the loss that a player will incur under the hypothetical conditions of playing an *indefinite*, or more precisely, an *infinite* number of hands. Furthermore, this assumes that the rule variation being prescribed is being used, and as there may be minor variations to the rule from casino to casino, and this is one source of variation in the stipulated House \"Edge\" calculations. Are there any other sources of variation in the House \"Edge\"?\n",
    "\n",
    "* \"the House \"Edge\" can fluctuate widely (both for and against the house) depending on the techniques applied by individual players.\"\n",
    "\n",
    "The excerpt also states that the House \"Edge\" can, and most likely, will vary from the stipulated figures based on the technique that an individual is playing. Whilst not explicit, \"technique\" here refers to two components that will involve decision-making on the part of the player, namely the amount to wager, and the choice of action to take in each individual hand.\n",
    "\n",
    "There are acknowledgements about other conditions under which the expected value of a player's wager will vary from the figures stipulated under the House \"Edge\" in \"these figures will vary in certain playing conditions\", in the mention of \"normal patterns of play\", and also in the mention of \"best technique\" in the 1st and 3rd lines of the table.\n",
    "\n",
    "Crucially however, it is NOT specified what precisely \"certain playing conditions\", \"normal patterns of play\", nor \"best technique\" refers to.\n",
    "\n",
    "We will return to give more precise specification of under what conditions this can vary, together with the set of hypothetical conditions under which the House \"Edge\" applied when we outline the principles behind the \"Basic Strategy\". \n",
    "\n",
    "Bearing these caveats in mind, we are provisionally satisifed that the House \"Edge\" figures here can serve as an approximate heuristic reference point for our exposition. Signficantly, this is a general guide, and does not factor in the rule variations between casinos. \n",
    "\n",
    "In light of some of the rule variation between casinos, and in order to get a sense of how the calculated House \"Edge\" varies *between* casinos, we requested information from a sample of casinos in a UK metropolitan area and collated the results. The data we collected is contained in [insert table]. As these were informal telephone conversations, and allowing for the various errors that might occur in reporting, we provide documentary evidence of these confirmations in Appendices.\n",
    "\n",
    "* Highlight additional sources of variation, in brief.\n",
    "* Explain the role of a particular assumption on player behaviour.\n",
    "\n",
    "\n",
    "* Independent hands\n",
    "* Player playing perfect basic strategy\n",
    "* No specification of betting behaviour\n",
    "\n",
    "* Collect some official statistics as a guide.\n",
    "* Any official guidance?\n",
    "* Then individual casinos.\n",
    "* Any other *credible estimates*.\n",
    "\n",
    "* Clarifying the legal definition of a \"game of chance\"\n",
    "* Some legal clarity would be approrpriate as part of a finishing touch.\n",
    "* Distinction between 1968 and 2005 Act/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Player optimal strategies for decision and betting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we outline some preliminaries on \"expected value\", its role in the calculation of a \"Basic Strategy\", and the determination of the casino's House \"Edge\".\n",
    "\n",
    "The House \"Edge\" assumes that the player is playing a perfect \"Basic Strategy\". The actual calculation of the House \"Edge\" requires the calculation of the \"Basic Strategy\" first, then the House \"Edge\" arises naturally. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline of issues\n",
    "\n",
    "We aim to answer the following questions:\n",
    "\n",
    "* How is the House Edge and Basic Strategy calculated?\n",
    "\n",
    "* An introduction of the issues involved in Blackjack\n",
    "\n",
    "* What is the status of the game, and what methods have been used to \"attack\" the problem.\n",
    "\n",
    "* How do the methodologies differ?\n",
    "\n",
    "* What, if any, unique insights can you offer? \n",
    "\n",
    "* What are necessary tools you need to introduce to assist in thinking about the problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evolution of Basic Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Expected value of a wager from probability, statistics, decision theory.\n",
    "* Simple outline of contemporary Basic Strategy decision table\n",
    "* Characterisation of it (compostion vs total dependent), information set, zero-memory vs basic strategy\n",
    "* Acknowledge work of Baldwin, Manson, Thorp, Griffin, Wong; Blackjack community in general.\n",
    "* Mention areas of consensus/agreement, areas of small deviations, nature of the exercise in general.\n",
    "* Mention the search for the recursive algorithm to calculate it, work of Chongwu Ruan, Michael Shackleford.\n",
    "* Outline the main assumptions which are made in calculation of Basic Strategy, and also the House Edge.\n",
    "* Outline the main limitations of Basic Strategy.\n",
    "* Reported statistics from Blackjack community about he House Edge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected value of a wager."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key concept from probability, statistics and decision theory that both the academic and Blackjack community rely on for their results is the notion of the expected value of a wager. We will place a simple coin flipping game within the framework of frequentist probability theory (and decision theory) to illustrate this.\n",
    "\n",
    "A frequentist statistician offers you the opportunity to participate in a wager on the outcome of a coin flip. You must pay £1 to participate, and he pays out £2 if the outcome is heads, but you lose your wager if the outcome is tails.  We also *assume* that the coin is fair, so that the probability of the coin landing on heads can be assigned a probability of 1/2, and the probability of the coin landing on tails is 1/2 also. Can we make any statements about what we expect to win or lose *on average*, if we were to particpate?\n",
    "\n",
    "The frequentist answer to this question would be to encode the potential gain and loss from the wager into a random variable:-\n",
    "\n",
    "$$ X =\n",
    "\\begin{cases}\n",
    "£2 & \\text{if coin lands on heads} \\\\\n",
    "£{-1} & \\text{if coin lands on tails} \\\\\n",
    "\\end{cases}$$\n",
    "\n",
    "The expected value of the wager then is a probability weighted average over possible all outcomes the random variable could take:\n",
    "\n",
    "$$ \\mathbb{E}_{p(X)}{\\left[X\\right]} = \\frac{1}{2} \\cdot (-2) + \\frac{1}{2} \\cdot (-1) = £0.50 $$\n",
    "\n",
    "Under the frequentist model of probability, the wager has positive expected value of £0.50, that is on average, we would expect to win £0.50 from playing. Under decision theory, as this wager has postive expected value, we should participate; and if it were not positive, we should not participate in the wager.\n",
    "\n",
    "How can this be applied to Blackjack, and how is this related to Basic Strategy?\n",
    "\n",
    "We provide a copy of a Basic Strategy table from a UK Casino in the Appendices. It is a complete specification of the action (i.e. hit, stick, split, double) the player should take for every initial hand the player could receive, and every possible dealer up-card. As there are 10 possible dealer upcards {A, 2, 3, 4, ... Q, K} and 55 distinguishable two-card player hands, the Basic Strategy table specifies what the player should do for 550 situations. \n",
    "\n",
    "So if I have a {T, 6} in my hand, and the dealer has a {2}, Basic Strategy dictates that I should elect to stick.\n",
    "\n",
    "The House \"Edge\" calculation that casinos provide mostly assume that the player is playing a Basic Strategy. \n",
    "\n",
    "One might be tempted to conclude on this basis that with a House Edge of \"0.51%\" with 4 decks playing this Basic Strategy, we would \"on average\" lose £0.51 for every £10 wagered, as we initially did. At this stage, that may be the case, but *without further scrutiny* of how the Basic Strategy table is constructed, and how the House \"Edge\" is calulcated, it is not possible to know.\n",
    " \n",
    "In particular, the following needs to be clarified:-\n",
    "\n",
    "* Whether the House \"Edge\" remains the same after the player's initial cards have been dealt.\n",
    "* Whether the House \"Edge\" remains the same after the player has hit or split.\n",
    "* The sensitivity of the House \"Edge\" calculation to rule variations (e.g. number of decks, use of shuffling machines, insurance, surrender, dealer sticking on soft 17 etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How is the House \"Edge\" and Basic Strategy calculated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to answer these questions, careful scrutiny is required of how the House \"Edge\" and Basic Strategy are calculated. At this point, it is worthwhile reviewing previous literature on the subject, to which we now turn.\n",
    "\n",
    "It is now fairly well accepted in the Blackjack community that the first serious attempt to analyse optimal strategies for Blackjack was in a paper published in 1956 in the Journal of the American Statistical Association by Roger Baldwin, Wilbert Cantey, Herbert Maisel and James McDermott. There are a number of significant differences between the US variant of Blackjack contained therein which mean that their *results* are not generalisable to the UK variant of Blackjack which we are interested in. Namely, the dealer being dealt two cards, one face-up and one face-down card, with the latter known as the \"hole\" card in the Blackjack community. Furthermore, they assume a 52-card deck, and they do not allow resplitting, whereas our variant uses 4 decks and does permit resplitting to as many hands as the cards invite. \n",
    "\n",
    "However, these minor differences do not detract from the significance of the paper, as it is the *method* that the authors devise for the player's optimal strategy in terms of expectation that is applicable. Their key insight was to specify a set of minimum standing numbers as a function of the player's expectation from electing to draw a card, and on from electing to stand under a variety of cases. Those expectations are then defined in a piece-wise fashion as functions of the dealer's final total. They then provide a method for evaluating the dealer's probability of the dealer getting a final total in terms of the probability of an initial three card total, the probability of getting a final total conditional on a partial total (which may be the initial three card total?) and a means of relating the two.\n",
    "\n",
    "Signficantly, two important simplifying assumptions are made:\n",
    "\n",
    "1) Equiprobability - that the probability of drawing any card in the deck is 1/52.\n",
    "\n",
    "2) Sampling with replacement - no matter how many cards the player draws, the probability of receiving any particular card on the next draw is still 1/52.\n",
    "\n",
    "They emphasise the laborious nature of computing exact probabilities, and provide an example suggesting that the computation of the dealer probabilities under the simplifying assumptions do not affect the optimal drawing strategy. The remainder of the optimal strategy for soft hands, doubling down, and splitting are then dealt with as supplements to the optimal drawing strategy. To the best of our knowledge, they also provide what is the first specification of the player's mathematical expectation and variance for playing Blackjack under the strategy they define.  \n",
    "\n",
    "A further key simplication that they highlight is that their optimal strategy does not make use of information available in the hands of the players preceding her in the draw, and also, information from cards used in previous hands; and stressed the difficulty in using \"this information except in an intuitive, non-scientific manner.\"\n",
    "\n",
    "A number of refinements to Baldwin et al's first pass at Basic Strategy, and is contained in Edward Thorp's bestseller, Beat the Dealer. Thorp's book additionally provides exact tables of calculated expected values underpinning the Basic Strategy decision table; together with calculations of the players' advantage under Basic Strategy, and under other reported strategies; statistical information on a long run of hands playing Basic Strategy, a corroboration of Baldwin et al's results, and a heuristic argument about the finer details of how the calculated tables apply on average, focusing on the distinction between exact composition dependent totals and \"paper totals\".\n",
    "\n",
    "There are some extremely useful complete deck strategy tables listed expected values. However, they are also computed for th US variant of 52-card decks and for the situation where the dealer has a face-down \"hole card\".\n",
    "\n",
    "The work of Manson, Holder & Downton, Griffin, Wong. [DETAILS]\n",
    "\n",
    "Whilst all of these books are excellent and detailed, we noted that no explicit method was available for the calculation of the Basic Strategy table and House \"Edge\", and particularly for the UK variant which we are interested in.\n",
    "\n",
    "It's now necessary to clarify the landscape a little better. The Basic Strategy table in its familar form retains broad agreement from the Blackjack community and also from the academic community. However, from the perspective of an intrepid independent researcher, there are some complexities, mostly in the computation of precise expected values, such as accounting for the following:\n",
    "\n",
    "* Copious variants on rules\n",
    "* Presence of calculations often very detailed, but with no further specification on how they may be reproduced.\n",
    "* Differences in method of calculation (e.g. three card dealer totals in Baldwin).\n",
    "* Compounded by potetntial presence of hidden assumptions that cannot be scrutinised due to lack of reproducible methodology.\n",
    "\n",
    "Whilst perhaps this may be explained by the perception that Blackjack is on the whole a \"solved\" game, in the sense that a Basic Strategy and Advantage Strategies exist...\n",
    "\n",
    "Furthermore, whilst Thorp, Griffin and Wong give fairly comprehensive and precise estimations of the House \"Edge\" that can be adjusted to account for the above, such as rule variants, number of decks used etc.; and in some give a few representative examples of how it is calculated, the position we take is that these figures are taken on trust, until we are able to reproduce the calculations to a fair degree of accuracy, or are satisfied with the logic of how our calculations are reached. Whilst Thorp, Griffin and Wong are all of signficant intellectual stature, to cast aside critical scrutiny and suppress scepticism on this basis goes against the grain of the search for clarity. Furthermore, once an initial benchmark is tested and documented for ourselves, we are in a better position to assess the validity of their reported statistics, as from an outsider's perspective, they do seem fairly consistent with another. \n",
    "\n",
    "We also believe that the kinds of comments made in Downton and Holder (1972) reflect some of our concerns about calculation methodologies not being made available. From our research, it is evident that these calculations are available somewhere, and from Thorp's book, these were shared in the Blackjack community. There is also mention that these calculations may exist in certain references by Braun and Wilson, which were unable to procure. \n",
    "\n",
    "All of this may be an artefact of the references we decided to sample as part of the process of writing this. Indeed, there may exist precise calculations in more specialised newsletters from the Blackjack community. \n",
    "\n",
    "Initially, our goal was to investigate the questions described above, and reproduce the UK House \"Edge\" under Basic Strategy, and the player advantage under an Advantage Strategy using simulation. Having tried a million rounds and gotten within a certain number, we re-evaluated why it was that our simulations were not getting similar numbers to those reported. We listed a number of reasons, but more importantly, we re-evaluated whether it was at all reasonable for reasons other than those listed (functional errors, statistical sampling error, deficient random number generation) to expect our simulation results to reflect that of the UK House \"Edge\". Without further information on how the House \"Edge\" and Basic Strategy results are calculated, and owing to the combinatorial nature of the Blackjack game, we felt that it was worthwhile attempting to reproduce these calculations for ourselves, as a better understanding would place us in a better position to evaluate whether our simulations results could reasonably be expected to match the calculations. It was also intially assumed that the House \"Edge\" and Basic Strategy statistics were derived via simulation, rather than analytically.\n",
    "\n",
    "This went against the original objective of our study, as our \"red line\" was not to get heavily involved in finer heuristic arguments, attempts to generalise results to gameplay, and also heavy combinatorics calculations. \n",
    "\n",
    "However, we felt that at some point, we judged that it was also against the spirit of clarity and rigour to completely avoid combinatorics calculations altogether. Our revised position then was to use combinatorics to get an illustrative idea of the complexity of the game, and to attempt some calculations manually.\n",
    "\n",
    "Having become aware that there may exist analytic calculations, we endeavoured to reconstruct and to find them. We began some elementary calculations but found them intractable, with difficulty varying on how we tried to define the sample space. Having read the Baldwin paper, and some parts of Griffin, and also Manson, and tried unsucessfully to deal with the combinatorial complexity, we broadened our research scope, and later became aware that there was a simple recursive algorithm that was available for our purposes.\n",
    "\n",
    "We outline some illustrations that an investigator thinking about the computation of Basic Strategy tables will experience when they give the problem independent thought prior to looking at any papers. In that vein, it will better highlight the simplicity and innovative nature of Baldwin et al's work. \n",
    "\n",
    "We also found some tutorials from the Blackjack Community, not the academic community, illustrating a method for calculating the Basic Strategy, the Wizard of Odds. Unless one has thought the problem through for oneself, it is difficult to appreciate their ingenuity. In particular, the use of recursion to deal with a branching conditional probability tree that may go on for multiple draws. We were not able to appreciate the sophistication of the application of this method of recursion until we had thought through the problem ourselves. Furthermore, we were unconvinced by the lack of mathematical formalism. This was provided by Chong Wu Ruan. \n",
    "\n",
    "Our contribution is synthesise these two sources in one accessible place, to verify their logic (there were some typos), and also to adapt them to our variant of UK Blackjack as appropriate. We refer the reader to the Appendices for the details.\n",
    "\n",
    "Our findings are that the Basic Strategy and House \"Edge\" is only strictly applicable in the following senses:\n",
    "\n",
    "* It holds only for the player's initial hand and dealer-up card. That is the information set being used in this strategy only contains the initial hand ande dealer up-card.\n",
    "* For the calculations we provide, courtesy of Wizard of Odds and the primer from Ruan, it is assumed that the evaluation of expectations assumes sampling with replacement, and equiprobability.\n",
    "* Other than heuristic arguments given by Thorp in his book, and before addressing the issue of including previously discarded cards in the player's information set, it is unclear whether the player's advantage/House Edge is likely to change as we move further and further away from the idealised situation of a full deck, equiprobability and sampling with replacement. \n",
    "\n",
    "A number of ways of dealing with the sensitivity of the results to assumptions are proposed:\n",
    "\n",
    "* For reasons we will outline, it is possible to construct controlled simulations to test the extent to which the player's expectation is a good guide to actual winnings or losses in the presence of sampling with replacement, elaborated in Thorp\n",
    "* Thorp gives some heuristic examples of this.\n",
    "* This might involve some kind of sensitivity analysis tests - to elaborate.\n",
    "* Crucially, it will be necessary to compare the result of the player's expectation under the idealised conditions to various distributions of the shoe. \n",
    "* In this way we might be able to assess the extent of deviation from the results\n",
    "* The difficulty is that our combinatorial arguments will show that this is not time-efficient.\n",
    "\n",
    "\n",
    "* Another method might be to modify our calculations to various extents to allow for these granularities (i.e. a particular distribution of cards).\n",
    "* However, for every distribution, we will have to modify our calculations, and whilst Thorp's work alludes the possibility of creating an algorithm that can compute Basic Strategy for every distinguishable subset and distribution, we would in effect be conducting all of the calculations in the Appendix again and again for every subset of a particular distribution as it was progressively sampled without replacement from the distribution. \n",
    "\n",
    "\n",
    "* This would be an example of combinatorial complexity arising WITHIN a particular shoe. \n",
    "* We prefer a different method of approaching the problem, and this is documented in the section \n",
    "\n",
    "* Reservations about the model - Statistical model, probability as a model for uncertainty, Bayesian extension, States of nature\n",
    "* Qualify the basic-strategy table. \n",
    "* Check /outline the 550 player hand combo calculation.\n",
    "* The idea of an optimal strategy.\n",
    "* Elaborate on rules for US regarding peeking.\n",
    "* Splitting issue.\n",
    "* Do the Cuthbertson et al \"card experts\" provide information on expectation and variance? Can forward how rigour can overturn intuition and shoddy advice. \n",
    "* Acknowledge that the calculations need not be agonised over at this stage, as we will examine calculations for a more up-to-date variant.\n",
    "* Edge reported by Baldwin and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advantage play - HI-LO Card Counting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Illustrate the principle\n",
    "* Clear exposition of the insights that led from Basic Strategy to Dubner's HI-LO Card Counting, mathematically.\n",
    "* The Fundamental Theorem of Card Counting and the \"spectrum of opportunity\".\n",
    "* Discussion of Ethier's proof via martingales.\n",
    "* Correlation between a point-count system and the effect of removal.\n",
    "* Restrict the scope, cover Kelly Criterion later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A brief illustration of the principle of HI-LO Card Counting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class of advantage strategies, as opposed to stratagems, we now consider are known as \"card-counting\" methods. There are many different variants of this class of the method, but the variant we examine is known as \"HI-LO\" card counting. This variant was presented by Harvey Dubner at the 1963 Fall Joint Computer Conference, and built on the work Baldwin et al., Thorp, and a number of other figures at various industrial research laboratories.\n",
    "\n",
    "The essence of the HI-LO Strategy is founded on the following observations:-\n",
    "\n",
    "1) That the player's actual expectations fluctuates as the number of cards in the deck are depleted in favour of the House, but also in favour of the player.\n",
    "\n",
    "2) That there is a statistical regularity in this fluctuation, depending on the kinds of cards that have been removed.\n",
    "\n",
    "The HI-LO strategy then exploits these observations in a principled, but also practical manner by constructing a statistical indicator that compresses information about the player's advantage or disadvantage, known as the \"true count\". This is then used to inform the player's decisions, and also can be combined with a system for varying one's bets to leverage that advantage to the fullest extent.\n",
    "\n",
    "Brief description.\n",
    "\n",
    "What, if any relation is there between Basic Strategy, and HI-LO? There are three areas of similarity and difference.\n",
    "\n",
    "* Variations in player decisions.\n",
    "* Information set.\n",
    "* Betting behaviour.\n",
    "\n",
    "On the issue of player decisions, such as when to stand, hit, split, double down, surrender, or opt for insurance; the HI-LO Strategy can be thought of as \"exceptions\" to Basic Strategy. On the whole, the decisions are similar, but HI-LO gives some prescription on when deviating from the prescriptions of Basic Strategy are statistically favourable to the player. Situations of when to deviate from Basic Strategy arise because the player is additionally using the true count statistical indicator to make decisions. [EXAMPLE]\n",
    "\n",
    "On the nature of the information (set) being used. Basic Strategy is derived under assumptions of a complete deck, equiprobability of card drawing, and sampling with replacement. A player using Basic Strategy is therefore only using statistical information restricted to their current hand and the dealer's current up-card. In a strict sense, and without further experimentation, there is no reason (and in fact there are very good reasons not*) to rely on it as a giving an accurate guide to the player's expectations beyond the first hand of a complete deck.\n",
    "\n",
    "HI-Lo Strategy differs in that the amount of statistical information being used. When a player uses HI-LO Strategy, and relying on the true count as a source of information on when to deviate from Basic Strategy (and in informing their bets), they are using information about all cards that have been dealt from the shoe to inform their decisions, albeit in a compressed form.\n",
    "\n",
    "On betting behaviour. Basic Strategy is silent and gives no prescriptions on how the player should be betting in each round. The calculations of Basic Strategy we have synthesised all make the assumption of a unitary bet, and therefore this can be multiplied by a constant factor to account for bets of varying sizes. It therefore assumes that the player is betting a constant amount each hand. \n",
    "\n",
    "In HI-LO Strategy, the true count statistical indicator only gives a measure of the player's advantage for a particular shoe, at a particular point in the shoe as a function of the unseen cards in the deck, and the number of cards that are favourable for the player. By itself, it gives no prescription on how to bet, and must be combined with an informal \"betting staircase\" so that the opportunities indicated by the true count can be leveraged to their fullest extent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How were these observations made? - a review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now review how observations 1) and 2) were made through a survey of the literature. This gives insight on how later authors went beyond the limitations of Basic Strategy to develop HI-LO Card Counting. This will allow scrutiny as to the epistemological status of these observations, and therefore the HI-LO Strategy as a whole from a more rigorous perspective.\n",
    "\n",
    "Baldwin et al.'s paper suggested a promising direction for future research, and they stated that \"the optimum strategy was developed under the assumption that the player does not have the time or incliniation to utilise the information available in the hands of the players preceding him in the draw. This information is non-existent when the player sits on the dealer's left and is greatest when the player is on the dealer's right. There are tremendous difficulties, however, in using this information except in an intuitive, non-scientific manner.\" \n",
    "\n",
    "The authors therefore acknowledge the possibility of using information of cards dealt to other players before the player has been dealt their hand. Edward Thorp went on to explore a development of this possibility - that of using not just information about the cards dealt in the current round, but the larger subset of cards that had been dealt.\n",
    "\n",
    "In a paper published in 1960, Thorp went on to investigate Baldwin et al's results on Basic Strategy for particular subsets of the Blackjack deck. The scope of the combinatorial complexity was also quantified - he calculated that there were 3.4 x 10^7 distinguishable subsets for a 52-card Blackjack deck. More significantly, whilst a granular calculation of the player's expectation is indeed possible for a particular subset, he noted that it was intractable to do so for all possible subsets. Thorp's way of dealing with this combinatorial intractability is a familiar one, and involves qualitative investigation of representative cases[FOONOTE]. The representative cases he investigated were classes of subsets where particular classes of cards were removed, using Q-notation. A table of this is reported in this paper, and an updated version is provided in Thorp's later published book*. This paper can be seen as an empirical precursor to their later work, and can be understood as an attempt to assess exploitable statistical regularities in how a player's expectation changes in response to the removal of different classes of card.\n",
    "\n",
    "In statistical and probabilistic terms, this can be viewed as a relaxation of the equiprobability and sampling without replacement aspects of Basic Strategy. More specifically, examination of how the player's expectations fluctuates according to the number and type of cards that have been removed from play can be viewed as a situation of dependent (rather than independent) trials; and of sampling with replacement (rather than without replacement).\n",
    "\n",
    "Classes of games falling under dependent trials and sampling with replacement other than Blackjack are baccarat, trente-et-quarante, and poker. \n",
    "\n",
    "After the publication of Beat the Dealer, Thorp and Walden (1973) formalised these insights mathematically, which they coined as the \"Fundamental Theorem of Card Counting\".\n",
    "\n",
    "Formally, successive hands of Blackjack in a particular shoe can be viewed as instances of dependent trials in which cards are drawn from the shoe without replacement. At the start of each hand, the player will have knowledge of $c$ cards that have been dealt, and there will be a corresponding probability distribution $F_c$ over the player's expectation*. The key insights of the Fundamental Theorem of Card Counting, presented in Thorp (1969) and in Thorp and Walden (1973), and also in Epstein (2007) are that:-\n",
    "\n",
    "* As knowledge $c$ of the cards increases, the \"spread\" of the probability distribution $F_c$ over player expectations increases. That is the variance of the player expectations random variable for partially depleted decks increases as the deck beomces progressively more depleted. \n",
    "\n",
    "* The average player expectation is non-decreasing with increasing depletion.\n",
    "\n",
    "* The conditional means $E(F_c | F_{c-k}); k = 1,2,3,...,c$ of the successive distributions $F_c$ are non-decreasing. \n",
    "\n",
    "* The distributions $F_c$ are dependent, and in particular when a deck does \"good\", it tends to stay good.\n",
    "\n",
    "* A \"spectrum of opportunity\" is created where the spread in $F_c$ can be exploited by placing large bets when the expectation is positive, and small bets when it is negative.\n",
    "\n",
    "* In contrast, basic strategy, will yield an expectation of $E(F_c)$ of +0.13%.\n",
    "\n",
    "A mathematical proof of this is given in Thorp and Walden, but is rather involved, making technical arguments using convex contraction of measures and combinatorial analysis which we do not have the means to thoroughly scrutinise. \n",
    "\n",
    "For now we will have to take the absence of a publicised response to the proof were it to be invalid as evidence that it enjoys acceptance by the mathematical community. In this case, our scepticism requires a greater degree of knowledge and fluency in a mathematical subfield than we can afford. So we will have to be content with lowering our scepticism on this particular front, and book the caveat appropriately.\n",
    "\n",
    "Even though we are unable to formally verify Thorp and Walden's results, we can make some comments on its scope. In its most native form, Thorp and Walden's result is a general one. For a particular situation where we have dependent trials and sampling without replacement, the distribution of player expectations \"spreads\" out when cards are depleted, and that average player expecation, using full knowledge of the cards before is non-drecreasing (or increasing under certain hypotheses) with increasing depletion. \n",
    "\n",
    "Whilst this a general, proven mathematical theorem which applies to all situations that were specfied, it is silent on the question of how specific classes of cards affect the player's expectation. In order to answer that question, investigation of a more empirical nature needs to be undertaken.\n",
    "\n",
    "A parallel strain of related work in 1960s in the statistics and information theory academic community, notably John Kelly (1956) and Leo Breiman (1961) examined the optimality of....\n",
    "\n",
    "* Shuffling machine\n",
    "* Concrete reasons for not being able to rely on Basic Strategy outside of the first hand of a complete deck.\n",
    "* Verify the calculation 3.4 x 10^7 subsets. \n",
    "* Decision to provide a table for distinguishable subsets?\n",
    "* Thorp (9169) specifies that the probability distribution is over expectations for the next hand, whilst Epstein doesn't specify\n",
    "* Throp and Walden (1973) is in context of baccarat. Can it be generalised to blackjack? Requires a thorough engagement with the proof. \n",
    "* Heuristic examples as a substitute for mathematical proof?\n",
    "* Can tighthen up the notation from Thorp and Walden. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Fundamental Theorem of Card Counting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the absence of the technical expertise required to evaluate Thorp and Walden's result, further investigation was undertaken in to the nature of the Fundamental Theorem of Card Counting. As part of our review, an alternative, excellent proof of the theorem is given in Ethier (2010) and Ethier and Levin (2005). We present their results here without proof, which can be found in the papers. Ethier and Levin's (2005) version of Thorp and Walden's result in (1973) is accessible for those who are not familiar with measure theory, but it does rely on some more concepts in stochastic processes such as martingales; and properties of random variables such as exchangeability; and groups and permutation notation. Most of this presentation is reproduced from Ethier (2010), with some minor additional exposition on our part. Any subsidiary theorems and preliminaries which are required are provided for ease of reference in the Appendices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first require setting up the appropriate mathematical formalisms to be able to state the Fundamental Theorem of Card Counting.\n",
    "\n",
    "* Assume that there is a deck of $N$ distinct cards, labelled from $1, 2,..., N$.\n",
    "* Label the positions of the cards so that the first card dealt is the card in position 1, the second card dealt is in position 2, all the way to the last card being dealt being in position $N$.\n",
    "* Before any shuffling happens, the order of the cards is in natural order $(1, 2, 3,...,N)$ to begin with.\n",
    "* Let $\\Pi$ be an $S_N$-valued random variable with the discrete uniform distribution (i.e. all $N!$ possible values are equally likely).\n",
    "* A random permutation $\\Pi$ is applied, and the order after shuffling is $(\\Pi^{-1}(1), \\Pi^{-1}(2),..., \\Pi^{-1}(N))$\n",
    "* Define $X_j := \\Pi^{-1}(j)$ for $j= 1,...,N$ so that $X_j$ is the label of the card in position $j$.\n",
    "* By theorem 11.2.1(a), $X_1, X_2,...,X_N$ is an exchangeable sequence.\n",
    "* A consequence of this is that $(X_{\\pi(1)}, X_{\\pi(2)},...,X_{\\pi(N)})$ has the same distribution as $(X_1, X_2,...,X_N)$, for every permutation $\\pi \\in S_N$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Fundamental Theorem of Card Counting (fixed strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Consider a game that requires up to $m$ cards to complete a round, and assume that the deck is reshuffled if fewer than $m$ cards remain.\n",
    "* Assume that the player plays a fixed strategy, i.e. one that does not depend on cards already seen.\n",
    "* Let $X_1, X_2,...,X_N$ be defined as above.\n",
    "* If the first $n$ cards have been seen $(0 \\leq n \\leq N-m)$, and the player bets on the next coup, his profit per unit bet has the form:\n",
    "\n",
    "$$Y_n := f(X_{n+1}, X_{n+2},...,X_{n+m})$$\n",
    "\n",
    "* Here, $f$ is a suitable nonrandom function.\n",
    "* The player's expected profit per unit bet is:\n",
    "\n",
    "$$Z_n := \\mathbb{E}[Y_n | X_1, X_2,..., X_n] = \\mathbb{E}[f(X_{n+1}, X_{n+2},...,X_{n+m})| X_1, X_2,..., X_n]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the assumptions we have made, the sequence $\\{Z_n\\}_{n=0, 1,..., N-m}$ is a *martingale* with respect to $\\{X_n\\}_{n=1,...,N-m}$. In particular:\n",
    "\n",
    "$$\\mathbb{E}[Z_0] = \\mathbb{E}[Z_1] = ... = \\mathbb{E}[Z_{N-m}]$$\n",
    "\n",
    "and\n",
    "\n",
    "$$ 0 = \\text{Var}(Z_0) \\leq \\text{Var}(Z_1) \\leq ... \\leq \\text{Var}(Z_{N-m})$$\n",
    "\n",
    "Let $I$ be an interval such that $P(Z_0 \\in I, Z_1 \\in I,..., Z_{N-m} \\in I)$. If $\\varphi : I \\mapsto \\mathbb{R}$ is convex, then the sequence $\\{\\varphi(Z_n), n = 0, 1,..., N-m \\}$ is a submartingale with respect to $\\{X_n\\}_{n=1, 2,...,N-m}$. In particular:\n",
    "\n",
    "$$\\mathbb{E}[\\varphi(Z_0)] \\leq \\mathbb{E}[\\varphi(Z_1)] \\leq ... \\leq \\mathbb{E}[\\varphi(Z_{N-m})]$$\n",
    "\n",
    "Finally, for each inequality in (11.69), the inequality is strict unless  both sides of the inequality are 0. If $\\varphi$ is strictly convbex, then for each inequality in (11.70), the inequality is strict unless both sides of the corresponding inequality in (11.69) are 0.\n",
    "\n",
    "* Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fundamental Theorem of Card Counting (variable strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For the general case of a variable strategy, assume that the player has a number of strategies available and therefore a number of possible choices of nonrandom funciton $f$ in (11.66).\n",
    "* With $m$ defined as before, we use $S$ to denote the set of such functions $f$.\n",
    "* Assume that $S$ is finite.\n",
    "* If the fist $n$ cards have been observed $(0 \\leq n \\leq N-m)$ and the player bets on the next coup, we assume that she chooses the optimal strategy $f^* \\in S$.\n",
    "* This will depend on $X_1, X_2,...,X_n$, so we denote it by $f^*_{X_1, X_2,...,X_n}$.\n",
    "* Optimality means that:\n",
    "\n",
    "$$\\mathbb{E}[f^*_{X_1, X_2, ..., X_n}(X_{n+1}, X_{n+2},...,X_{n+m})| X_1, X_2,..., X_n] \\geq \\mathbb{E}[f_{X_1, X_2, ..., X_n}(X_{n+1}, X_{n+2},...,X_{n+m})| X_1, X_2,..., X_n]$$\n",
    "\n",
    "for every possible choice $f_{X_1, X_2, ..., X_n} \\in S$. \n",
    "\n",
    "The player's profit per unit bet is then:\n",
    "\n",
    "$$Y_n := f^*_{X_1, X_2, ..., X_n}(X_{n+1}, X_{n+2},...,X_{n+m})$$\n",
    "\n",
    "And her conditional expected profit per unit bet is then:\n",
    "\n",
    "$$Z_n := \\mathbb{E}[Y_n | X_1, X_2,..., X_n] = \\mathbb{E}[f^*_{X_1, X_2, ..., X_n}(X_{n+1}, X_{n+2},...,X_{n+m})| X_1, X_2,..., X_n]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the above assumptions, the sequence $\\{Z_n\\}_{n=0, 1,...,N-m}$ is a *submartingale* with respect to $\\{X_n\\}_{n=1,2,...,N-m}$. In particular:\n",
    "\n",
    "$$\\mathbb{E}[Z_0] \\leq \\mathbb{E}[Z_1] \\leq ... \\leq \\mathbb{E}[Z_{N-m}] $$\n",
    "\n",
    "More generally, let $I$ be an interval such that $P(Z_0 \\in I, Z_1 \\in I,..., Z_{N-m} \\in I) = 1$. If $\\varphi : I \\mapsto \\mathbb{R}$ is convex and nondecreasing, then the sequence $\\{\\varphi(Z_n)\\}_{n=0,...,N-m}$ isa submartingale with respect to $\\{X_n\\}_{n=1,2,...,N-m}$. In particular:\n",
    "\n",
    "$$\\mathbb{E}[\\varphi(Z_0)] \\leq \\mathbb{E}[\\varphi(Z_1)] \\leq ... \\leq \\mathbb{E}[\\varphi(Z_{N-m})]$$\n",
    "\n",
    "Finally, if $\\varphi$ is strictly convex and increasing, then for $n= 0, 1,..., N-m-1$, $\\mathbb{E}[\\varphi(Z_n)] = \\mathbb{E}[\\varphi(Z_{n+1})]$ if and only if $Z_n$ and $Z_{n+1}$ are constant and equal.\n",
    "\n",
    "* Remarks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making use of these observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we make use of these observations?\n",
    "\n",
    "In practice, we use a simpler statistic that the conditional expected profit per unit bet, $Z_n$ as a gauge of player of advantage. \n",
    "\n",
    "Define $e(j)$ as the *effect of removal* of the $j$th card, where $j = 1, 2,...,N$. Then, following the notation above:\n",
    "\n",
    "$$\\begin{align}\n",
    "e(j) :&= \\mathbb{E}[Y_1 | X_1 = j] - \\mathbb{E}[Y_0] \\\\\n",
    "      &=  \\mathbb{E}[f(X_2,X_3,...,X_{m+1}) | X_1 = j] -  \\mathbb{E}[f(X_1,X_2,...,X_{m})]\n",
    "\\end{align}$$\n",
    "\n",
    "We then make the following hypothesis.\n",
    "\n",
    "* Let $D$ be the set of cards ${1, 2,...,N}$.\n",
    "* Assume that to each card $j \\in D$ an associated number $c(j)$ is assigned such that the the player's expected profit per unit bet on the next coup is given by:\n",
    "\n",
    "$$E_U = \\frac{1}{|U|}\\sum_{j \\in U}{c(j)} + \\epsilon_U$$\n",
    "\n",
    "* Define $\\mu := E_D$ as the full-deck expectation, we find that:\n",
    "\n",
    "$$\\begin{align}\n",
    "c(j) &= \\sum_{i \\in D}{c(i)} - \\sum_{i \\in D \\backslash \\{j\\}}{c(i)} \\\\\n",
    "     &= N\\mu - (N - 1)E_{D \\backslash \\{j\\}} \\\\\n",
    "     &= \\mu - (N-1)(E_{D \\backslash \\{j\\}} - \\mu) \\\\\n",
    "     &= \\mu - (N-1)e(j), \\quad j = 1, 2,..., N \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "* Since $\\sum^{N}_{j=1}{e(j)} =0$, it follows that, when $X_1, X_2,...,X_n$ have been seen, $\\widehat{Z_n}$, the player's conditional expected profit per unit bet on the next coup under the above hypothesis, is:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\widehat{Z_n} :&= \\frac{1}{N-n} \\sum^{N}_{j=n+1}{\\{\\mu - (N-1)e(X_j)\\}} \\\\\n",
    "               &= \\mu + \\frac{1}{N-n} \\sum^{n}_{j=1}{(N-1)e(X_j)}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical justification of the hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quantities $\\mu - (N-1)e(j)$ in (11.75) are the least squares estimators of the parameters $c(j)$ in the linear model:\n",
    "\n",
    "$$ E_U = \\frac{1}{|U|}\\sum_{j \\in U}{c(j)} + \\epsilon_U, \\quad U \\subset D, |U| = N-n$$\n",
    "\n",
    "for fixed $n$, $1 \\leq n \\leq N-m$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Should I include Proof and justification here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the derivation of the player's conditional expected profit per unit bet on the next coup, assuming the hypothesis above, we can apply a particular variant of the Central Limit Theorem for samples from a finite population to (11.76), and letting $\\sigma^2_{e}= Var(e(X_1))$, we have:\n",
    "\n",
    "$$\\frac{\\widehat{Z_n} - \\mu}{\\sigma_e \\sqrt{n(N-1)(N-n)}} \\overset{D}{\\to} N(0,1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, the quantities $E_i := (N-1)e(i)$ of (11.76) are replaced by integers $J_i$ that are highly correlated with the given numbers and for which $J_1 + J_2 + ... + J_N = 0$. Such a card counting systems is said to be *balanced*. Writing (11.76) as:\n",
    "\n",
    "$$ \\widehat{Z_n} = \\mu + \\frac{1}{N-n}\\sum_{j=1}^n{E_{X_j}}$$\n",
    "\n",
    "We approximate $\\widehat{Z_n}$ by replacing each $E_{X_j}$ with $J_{X_j}$ and a coefficient $\\gamma$:\n",
    "\n",
    "$$ {Z^*_n} := \\mu + \\gamma \\left(\\frac{1}{N-n}\\sum_{j=1}^n{J_{X_j}}\\right)$$\n",
    "\n",
    "where the coefficient is given by:\n",
    "\n",
    "$$ \\gamma = \\frac{\\sum^N_{i=1}{E_i J_i}}{\\sum^N_{i=1}{E^2_i}} = \\rho \\frac{\\sigma_E}{\\sigma_J} $$\n",
    "\n",
    "* Here, $\\rho$ is the correlation between $E_{X_1}$ and $J_{X_1}$.\n",
    "* $\\sigma_E$ and $\\sigma_J$ are the standard deviations of $E_{X_1}$ and $J_{X_1}$ \n",
    "* Parameter $\\gamma$ is a *regression coefficient*, and can be estimated via ordinary least squares, specifically, choosing $\\gamma$ to minimise the sum of squared residuals:\n",
    "\n",
    "$$\\hat{\\gamma} = \\underset{\\gamma}{\\text{argmin}} \\sum^N_{i=1}{(E_i - \\gamma J^2_i)}$$\n",
    "\n",
    "The quantity within parentheses (11.95) is the *true count*. It must be adjusted by the constants $\\gamma$ and $\\mu$ to estimate the player's advantage. A *level-k* card counting system uses integeres whose maximum absolute value is $k$. Level-one systems are the most popular.\n",
    "\n",
    "Similar to above, we can apply the same variant of the Central Limit Theorem for samples from a finite population to $Z^*_n$ as well. We have:\n",
    "\n",
    "$$ \\frac{Z^*_n - \\mu}{\\gamma \\sigma_J} \\sqrt{\\frac{(N-n)(N-1)}{n}} \\overset{D}{\\to} N(0,1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $J_{X_1}$ is integer valued, we can improve any Normal approximation with a continuity correction.\n",
    "\n",
    "With this, we can approximate two more quantities of interest:\n",
    "\n",
    "* The probability that a superfair bet is available after $n$ cards have been seen.\n",
    "* The expected profit available per unit bet after $n$ cards have been seen.\n",
    "\n",
    "Assuming that the player bets one unit of the bet is superfair, and nothing if its subfair, we need to approximate $\\mathbb{E}[(Z^*_n)^+]$.\n",
    "\n",
    "Via the above application of the Central Limit Theorem, $Z^*_n$ is asymptotically Normal with mean $\\mu$ and the following variance:\n",
    "\n",
    "$$\\sigma_n := \\frac{\\gamma^2 \\sigma^2_J n}{(N-n)(N-1)}$$\n",
    "\n",
    "Denoting the left hand-side of (11.98) by $\\zeta_n$, we obtain the following approximation:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mathbb{E}[(Z^*_n)^+] &= \\mathbb{E}[(\\mu + \\sigma_n \\zeta_n)^+] \\\\\n",
    "                      &\\approx \\frac{1}{\\sqrt{2 \\pi}} \\int^{\\infty}_{- \\infty}{(\\mu + \\sigma_n \\zeta)^+ e^{-\\zeta^2 / 2}d \\zeta} \\\\\n",
    "                      &= \\frac{1}{\\sqrt{2 \\pi}} \\int^{\\infty}_{- \\mu / \\sigma_n}{(\\mu + \\sigma_n \\zeta) e^{-\\zeta^2 / 2} d \\zeta} \\\\\n",
    "                      &= \\mu(1 - \\Phi(-\\mu / \\sigma_n)) + \\sigma_n\\phi(-\\mu / \\sigma_n) \\\\\n",
    "                      & = \\mu\\Phi(\\mu / \\sigma_n) + \\sigma_n \\phi(\\mu / \\sigma_n)\\end{align}$$\n",
    "                      \n",
    "where\n",
    "\n",
    "$$ \\phi(z) := \\Phi'(z) = (2 \\pi)^{-1 / 2}e^{-x^2 / 2}$$\n",
    "\n",
    "is the standard-normal density function. It must be acknowledged that the above approximation is not fully justified, but it will prvoe useful nonetheless. Notice that the right hand side of (11.100) is always positive, even if $\\mu$ is negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making use of the theory to develop an effective system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the preceding section, we evaluated $E$, the expected profit from an initial one-unit blackjack wager, asssuming composition-dependent basic strategy, when the deck is full.\n",
    "\n",
    "Denote by $E(\\mathbf{m})$, where $\\mathbf{m} = (m_1, m_2,...,m_{10})$, the expected profit from an initial one-unit blackjack wager, assuming composition-dependent basic strategy, when the full deck is depleted by $m_1$ aces, $m_2$ twos,...,$m_10$ ten-valued cards. On this basis we have that $E(\\mathbf{0}) = E$. Of course we would anticipate that basic strategy (optimised for the full deck) is suboptimal for every deck other than the full dekc.\n",
    "\n",
    "Substantial computing effort, we evaluate the *effects of removal* on the expected profit from an initial one-unit blackjack wager, assuming composition-dependent basic strategy:\n",
    "\n",
    "$$\\text{EoR}(i) := E(\\mathbf{e_i}) - E(\\mathbf{0}), \\quad i = 1, 2,..., 10$$\n",
    "\n",
    "Here $\\mathbf{e_1} := (1, 0,...,0)$, $\\mathbf{e_2} := (0, 1,...,0)$, and so on. The numbers (21.66), multiplied by 100 are listed in Table 21.9. Notice that:\n",
    "\n",
    "$$\\text{EoR}(1) + \\text{EoR}(2) + ... + \\text{EoR}(9) + 4\\text{EoR}(10) = 0$$ \n",
    "\n",
    "For a *balanced* card-counting system, the sum of the point values over the entire deck is 0. For the system $(J_1, J_2,...,J_{10})$, this means that:\n",
    "\n",
    "$$J_1 + J_2 + ... + 4J_{10} = 0$$\n",
    "\n",
    "Table 21.9 lists five balanced card-counting systems, namely the Hi-Lo, HI-Opt I, Zen, Halves, and Ultimate Systems. Listed as well are two unbalanced systems, the Knock-Out and the Noir systems. In each case we indicate the corelation with the effects of removal.\n",
    "\n",
    "We next use a Normal approximation to approximate the probability that the player's estimated advantagem based on the HI-LO card-counting system, exceeds a certain level as a function of the number of cards seen.,\n",
    "\n",
    "Let $Z^*_n$ denote the player's estimated expected profit on the next hand based on the true count after $n$ cards have been seen. Then by (11.94):\n",
    "\n",
    "$$Z^*_n := \\mu + \\frac{\\gamma}{52}\\left(\\frac{52}{52-n}\\sum^n_{j=1}{J_{X_j}} \\right) = \\mu + \\frac{\\gamma}{52}\\text{TC}_n$$\n",
    "\n",
    "where $X_1, X_2,...,X_{52}$ is the sequence of card values in the order in which they are exposed, $(J_1, J_2,...,J_{10}) := (-1, 1, 1, 1, 1, 1, 0, 0, 0, -1)$ is the vector of HI-LO point count values, and $\\mu = E$ is the full-deck expectation,\n",
    "\n",
    "$$\\gamma := \\frac{\\sum^{10}_{i=1}{w_i E_i J_i}}{\\sum^{10}_{i=1}{w_i J^2_i}} \\approx 0.259932$$\n",
    "\n",
    "is the regression of (11.96) where $w_1 = w_2 = ... = w_9 := 4/52$, $w_{10} := 16/52$, and $E_i := 51\\text{EoR}(i)$, and finally $\\text{TC}_n$ is the true count, the quantity within parentheses in (21.69). The adjustment accounts from the how it is most often interpreted in the Blackjack community; as the running count divided by the number of *decks*( that remain, not the number of *card* that remain, which explains the factor of 52.\n",
    "\n",
    "Then with $\\sigma^2 := \\sum^{10}_{i=1}{w_i J^2_i} = 10/13$,\n",
    "\n",
    "$$\\begin{align}\n",
    "P(Z^*_n > \\beta) &= P \\left (\\mu + \\frac{\\gamma}{52-n} \\sum^n_{j=1}{J_{X_j}} > \\beta \\right) \\\\\n",
    "                   &= P\\left ( \\sum^n_{j=1}{J_{X_j}} > \\left \\lfloor (52-n)\\frac{\\beta - \\mu}{\\gamma} \\right \\rfloor + \\frac{1}{2} \\right ) \\\\ \n",
    "                   &\\approx 1 - \\Phi \\left (\\frac{1}{\\sigma} \\left \\{ \\left \\lfloor (52-n) \\frac{\\beta - \\mu}{\\gamma} \\right \\rfloor + \\frac{1}{2} \\right \\} \\sqrt{\\frac{51}{n(52-n)}} \\right)\n",
    "\\end{align}$$\n",
    "\n",
    "where $\\Phi$ is the standard-Normal cumulative distribution function.\n",
    "\n",
    "We evaluate this function for several values of $n$ and $\\beta$ in Table 21.10. We hasten to add that these are based on three approximations, namely (11.74), (11.95) and (21.71).\n",
    "\n",
    "A better sense of Blackjack's earning potential can be found by applying (11.100), which apporximates the player's estimated expected profit when she bets one unit in situations perceived as favourable and nothing otherwise, as a function of the number $n$ of cards seen:\n",
    "\n",
    "$$\\mathbb{E}[(Z^*_n)^+] \\approx \\mu \\Phi (\\mu / \\sigma_n) + \\sigma_n \\phi(\\mu / \\sigma_n) $$\n",
    "\n",
    "where $\\sigma^2_n := \\gamma^2 \\sigma^2 n / [51(52-n)]$ and $\\phi$ is the standard-Normal density function.\n",
    "\n",
    "The expectation (21.72) is tabulated for the HI-LO System in Table 21.10. It is monotonic in n, which is to be expected in biew of the fundamental theorem of card counting (Theorem 11.3.4), esepcially (11.70).\n",
    "\n",
    "We conclude that card counting can turn blackjack - an essentially fair game for the basic strategies - into a proftiable one.\n",
    "\n",
    "Betting efficiency.\n",
    "\n",
    "Peter Griffin [1937-1998] (1976; 1999, Chapter 4), in perhaps his most important contribution to Blackjack, showed how to evaluate card-counting systems. He defined the *efficiency E* of a system to be \"the ratio of the profit accruing from the system to the total gain possible from perfect knowledge and intepretation of the unplayed set of cards\". He used (11.100) to estimate both the numerator and denominator, obtaining:\n",
    "\n",
    "$$ E = \\frac{\\mu \\Phi(\\mu / \\sigma_n) + \\sigma_n \\phi (\\mu / \\sigma_n)}{\\mu \\Phi(\\mu / \\sigma^*_n) + \\sigma^*_n \\phi (\\mu / \\sigma^*_n)}$$\n",
    "\n",
    "where $\\mu$ is the expectation at the next round and\n",
    "\n",
    "$$\\sigma_n := \\rho \\sigma_{e} \\sqrt{\\frac{n}{51(52-n)}} \\quad \\text{and} \\quad\\sigma^*_{n} := \\sigma_{e} \\sqrt{\\frac{n}{51(52-n)}} $$\n",
    "\n",
    "Here $\\rho$ is the correlation between the count system and the effects of removal, and $\\sigma^2_e$ is the weighted avberage of the squares of the effects of removal. Notice that (2181) reduces to $\\rho$ when $\\mu = 0$.\n",
    "\n",
    "This fomrula permits the evaluation of both the *betting efficiency* and the *playing efficiency* of a system. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal betting under the Kelly Criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Illustrate the principle.\n",
    "* Introduction to Kelly's paper.\n",
    "* Contextualise also with Breiman's work.\n",
    "* Use Thorp's 1992 paper to guide the exposition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief outline of rules and terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What inspired you to investigate Blackjack?\n",
    "* What are your broader motivations for investigating Blackjack?\n",
    "* Why do you think it is ripe to use the methods you have proposed?\n",
    "* What contribution can you make beyond what is already existing?\n",
    "\n",
    "My primary motivation for investigating the game of Blackjack, other than my own interest in the game, is as a means of developing and furthering my knowledge of applied mathematics. In particular, that of time-series analysis and stochastic processes. Furthermore, it provides an interesting, controlled setting and invites use of computational methods such as Monte Carlo methods as a necessity - a technique resulting from the study of phenomena that cannot be tackled using classical applied methods.\n",
    "\n",
    "Having already studied time-series methods in econometrics in context of an undergraduate university setting, I was uninspired. That is not an indictment of the instructor, nor the subject, but perhaps more symptomatic of the setting in which it was explored - that of training students to use a \"battery\" of methods (MA, AR, ARMA, GARCH, ARCH and the requisite alphabet soup of models) without regard for its intellectual history and context.\n",
    "\n",
    "That changed when I read a copy of Norbert Wiener's \"*Cybernetics, or Control and Communication in the Animal and the Machine*\". It is Wiener's thoughts on the conceptual foundations of time-series that made up for uninspiring university courses on the same subject. It is hoped that the following discussion will bind together the concepts and methods being investigated, by emphasising the threads that connect them. If the reader is not inclined to indulge in some history, they are free to move on to the next section.\n",
    "\n",
    "As a research scientist for the American military in WWII, the problem Wiener was faced with was that of increasing the accuracy of anti-aircraft guns at shooting down enemy aircraft. This required prediction of the aircraft's future position - due to the distance that the shell needs to travel between the gun and the aircraft. If one were to aim at the target's current position, by the time the shell reaches the position the gunner has aimed at, one will have missed. However, what information should we use to make this prediction? \n",
    "\n",
    "Perhaps we could use a model-based prediction, in the spirit of a mechanics problem, by using measurements of the aircraft's position, velocity, and acceleration. But how then could we account for evasive actions implemented in the behaviour of the pilot? Abstracting from this context, the problem of prediction from a time-series perspective then becomes *how we can use past measurements of a quantity distributed in time to make statistically optimal inferences about that quantity at some future point in time*.\n",
    "\n",
    "Modern time-series methods tend to be 'model-free', in the sense that they provide an abstract set of tools and a framework to characterise the statistical properties of measurements distributed in time without necessarily a model of the underlying physical process that generates these measurements.\n",
    "\n",
    "* Ensemble averages, time averages, and the ergodic theorem - simulation.\n",
    "\n",
    "* The \"statistical\" turn - statistical mechanics, the ergodic theorem, the challenge of modelling 6 x 10^23 particles\n",
    "* The role of computers - simulations, the Monte Carlo method, and their applicability to modern day problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first plot can be thought of as a time-series, showing the player's capital stock as a function of time.\n",
    "\n",
    "For most real-world time-series, this is the only *observable* time-series available. In our context, a time-series like this could in principle be obtained by going to a casino, playing 1,000 hands under a basic strategy, and keeping a running record of our chip count (capital stock).\n",
    "\n",
    "In the sense of *observability*, this is analogous to only being able to observe the daily closing prices of the FTSE 100. The FTSE-100 closing prices over the last century are one realisation of an ensemble of possible realisations, and it is only this that we observe. \n",
    "\n",
    "In our case with a player playing a perfect basic strategy, and fixed betting behaviour; the resolution of every hand within a shoe (i.e. between shuffles) is completely deterministic. In the sense that for any arbitrary two-card player hand, and a corresponding arbitrary dealer up-card, we can completely specify what the player and the dealer will do. Furthermore, we can also completely specify what the player and the dealer will continue to do if any further cards are drawn. \n",
    "\n",
    "The only source of randomness in our Blackjack model is the distribution of cards within the shoe, after it has been (re)shuffled. That is, if we were to know the distribution of cards within the shoe after shuffling has occurred every time it was shuffled, we would know with certainty what the player and the dealer would do, and would be able to forecast the player's capital stock with perfect certainty. It is because this distribution of cards is *unknown* at every time the shoe is shuffled that the randomness arises.\n",
    "\n",
    "However, even though we lack knowledge of the distribution of cards each time the shoe is shuffled, it is in a sense a known unknown. In that we can place hard constraints and limits on the extent of our ignorance. We know that at the start of each shoe, there will be 4/6, or any number of 52-cards decks being used etc. \n",
    "\n",
    "* Continue the distinction between incomplete information about stock markets vs blackjack later.\n",
    "\n",
    "The strategy of simulation in the blackjack example is that even though we do not know the exact distribution of cards in each shoe, we DO Have knowledge of the data generating process - that is *how* the data is generated - shuffle a deck of cards.\n",
    "\n",
    "* Can expand on degrees of ignorance, but key is to focus on the distinction between the process generating capital stock as a function of time vs the process generating FTSE closing prices as a function of time.\n",
    "\n",
    "Because we have knowledge of how the underlying process generating capital stock as a function of time, the simulation strategy assumes that we can mimick this underlying process. As we know that this underlying process is defined by our specification of the totality of player actions and dealer actions in every contingency under fixed betting behaviour, the crux of this mimicry lies in the extent to which we can simulate the physical act of shuffling the cards in the shoe with a *pseudo-random number generator*. The reliability of our Monte Carlo simulation then lies in the ability of our chosen PRNG to simulate this physical process, and this is not an altogether trivial issue.\n",
    "\n",
    "At this point, it is worthwhile making some distinctions between classical statistics, and computer science. It is common in most statistics courses, as far as the author is aware, to discuss Bayesian vs frequentist treatments of probability as representing degrees of belief in the former, and as the limit of relative frequencies in the latter, but not to explicitly discuss 'randomness'; and the unquestioning use of the term random variable is not seriously scrutinised. Nor does it need to be, as it is in most cases not relevant for the kinds of knowledge statisticians wish to generate. \n",
    "\n",
    "However, nuances which statisticians often need not concern themselves with cannot be overlooked in other contexts, such as when one needs to find a means of generating (pseudo)-random numbers that meet certain criteria, and when the success or failure of this means becomes critical. An example would be their use in cryptographic applications, such as the generation of keys in public-key cryptography. In our simulation case, if our pseudo-random number generator suffers from deficiencies, to be qualified, then we cannot be sure that, if we decide to study the statistical properties of our simulations, that our results suffer from a kind of systematic bias, and we end up with a study of the statistical properties of a defective random number generator, rather than our intended object of the study, the phenomenon we wish to simulate. \n",
    "\n",
    "* Can put in discussion after some review about what has been said on pseudo-random number generators; i.e. an assessment of how they might bias results, \n",
    "\n",
    "Given the above, Monte Carlo simulation allows us to generate a vast number of alternate realisations of the same stochastic process, and with the above caveats, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Related work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Literature review. Look for key papers that were published on card counting strategy for Blackjack from reputable sources i.e. journals, and good books.\n",
    "\n",
    "Primary goal of this mini review is to get a sense of the landscape of methodologies used to attack this problem. \n",
    "\n",
    "Some well-referenced sources collated in the Blackjack papers folder.\n",
    "\n",
    "Millman(1983) - Simulation and statistical analysis. 1,000 trials of 20,000 hands are simulated under a HI-LO card-counting strategy.\n",
    "\n",
    "Thorp (1960) - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we emphasise that we do not carry out exhaustive combinatorial analysis, but use it to give an illustration of the combinatorial complexity involved.\n",
    "\n",
    "* Combinatorial illustration\n",
    "* Strategy for assessing the long-run behaviour of player's capital under naive, Basic and Advantage strategy.\n",
    "\n",
    "* May need significant re-writing to simplify and use necessary results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that without further investigation into the sensitivity of Basic Strategy to changes in the equiprobability and sampling with replacement assumption; and given that we felt that we did not at this stage want to tackle the issue of within-shoe combinatorial complexity; but because we still wish to examine the long-run behaviour of players' capital, we decided to look to a slightly different method.\n",
    "\n",
    "Consider instead the number of possible distinguishable initial distributions of shoe that are available for 1 deck, 4 decks and 6 decks of cards. These would represent the initial distribution of cards/possible shufflings *before* any hands have been dealt.\n",
    "\n",
    "Illustrating this, one deck can be represented as:\n",
    "\n",
    "$$ \\left\\{A_1, A_2, A_3, A_4, 2_1, 2_2, 2_3, 2_4, ..., 10_1, 10_2, 10_3, 10_4, ..., K_1, K_2, K_3, K_4\\right\\}$$\n",
    "\n",
    "There will be 52! = 8.06 x 10^67 ways of reordering this deck, and that assumes that all cards are distinct objects. As under the rules of Blackjack, the suit is only a cosmetic difference, and because 10, J, Q, K are all of value 10, we have to account for this by representing one deck in the following way:-\n",
    "\n",
    "$$ \\{\\underbrace{A, A, A, A}_\\textrm{4 repetitions}, 2, 2, 2, 2, ..., \\underbrace{10, 10, 10, 10,..., 10, 10, 10, 10}_\\textrm{16 repetitions} \\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each card from A - 9, constituting 9 distinct cards by value, there will be 4 repetitions of each of those cards for each suit. And for cards from 10, J, Q, K, constituting 1 distinct card by value, there will be 16 repetitions of each of those cards for each suit. Therefore there will be the following number of possible distinguishable one deck ordered sequences of cards that we could start with before any shoe were to be played:-\n",
    "\n",
    "$$\\frac{52!}{(4!)^9 \\cdot 16!} = 1.45 \\cdot 10^{42}$$\n",
    "\n",
    "Using a similar calculation modified for 4 decks and 6 decks, we have $\\frac{208!}{(16!)^9 \\cdot 64!} = 2.47 \\cdot 10^{184}$ and $\\frac{312!}{(24!)^9 \\cdot 96!} = 1.56 \\cdot 10^{280}$ possible initial distributions of cards at the beginning of the shoe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The human mind cannot realistically comprehend numbers of this kind of magnitude. To get a sense of the scale of this number, the wikipedia estimate of the number of atoms in the observable universe is around $10^{80}$. Therefore the numbers of possible ordered sequences of cards in the shoe before any hands are played are for 4 and 6 decks, approximately 100 and 200 orders of magnitude greater than the number atoms in the observable universe. \n",
    "\n",
    "A transcomputational problem is a problem that requires processing of more than $10^{93}$ bits of information. Any number greater than $10^{93}$ is called a transcomputational number, or, Bremmerman's limit - the total number of bits processed by a hypothetical computer the size of the Earth within a time period equal to the estimated age of the Earth. Here is an excerpt \n",
    "\n",
    "\"The experiences of various groups who work on problem solving, theorem proving and pattern recognition all seem to point in the same direction: These problems are tough. There does not seem to be a royal road or a simple method which at one stroke will solve all our problems. My discussion of ultimate limitations on the speed and amount of data processing may be summarized like this: Problems involving vast numbers of possibilities will not be solved by sheer data processing quantity. We must look for quality, for refinements, for tricks, for every ingenuity that we can think of. Computers faster than those of today will be a great help. We will need them. However, when we are concerned with problems in principle, present day computers are about as fast as they ever will be.\n",
    "\n",
    "We may expect that the technology of data processing will proceed step by step – just as ordinary technology has done. There is an unlimited challenge for ingenuity applied to specific problems. There is also an unending need for general notions and theories to organize the myriad details.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bremmerman's limit and the combinatorial calculations provide us with a valuable signpost, gently guiding us away from applying brute force methods for the analysis of Blackjack. \n",
    "\n",
    "* Reservations about analytic arguments etc.\n",
    "\n",
    "We would like to explore whether we can make statements about the long-run behaviour of the player's capital under a naive, basic, and advantage strategy. Our style of analysis and method is in the spirit of Stanislaw Ulam, Nicholas Metropolis, John von Neumann; and more indirectly, Norbert Wiener and Claude Shannon. That is, in context of Monte-Carlo simulation, ensembles of time-series, the ergodic theorem, and some tools in statistical analysis. Making statements about the long-run behaviour of player capital consists of the following steps, provisionally (needs edit/refinement):\n",
    "\n",
    "* Split the Blackjack problem into a mixture of stochastic and deterministic processes. \n",
    "* Yielding three representative classes of ensembles of time series under naive, Basic and Advantage strategies.\n",
    "* Use Monte Carlo simulation to generate trajectories for each ensemble.\n",
    "* Examine the properties of one time-series from each ensemble and apply a relevant transformation.\n",
    "* Re-evaluate properties of each time-series; and if they are ergodic and stationary.\n",
    "* If these properties can be established, then we can use the LLN and the Central Limit Theorem to establish sample statistics for each representative class of ensemble. \n",
    "* Use the ergodic theorem to establish a connection between the statistical characterisation of the ensemble, and the time average of an arbitrary trajectory selected from the ensemble. \n",
    "\n",
    "The context in which Monte Carlo methods emerged has already been discussed. In this light, we can see an infinitely long run of Blackjack hands under naive, Basic and an Advantage strategy as a mixture of stochastic and deterministic components.\n",
    "\n",
    "The deterministic component is the resolution of an arbitrary shoe. For this arbitrary shoe, the entire sequence of hands under a particular strategy (i.e. a sequence of functions transforming player capital after each hand) can be concatenated and viewed as one composite transformation/function of the player's capital. \n",
    "\n",
    "The stochastic component is the sampling of an arbitrary shoe from one of 1.45 x 10^42 possible shoes. There will be correspondingly that 1.45 x 10^42 possible transformations for each shoe, and we can envisage this in principle (even though it will not be computationally tractable). The player's terminal capital can then be viewed as a random variable endowed with a probability distribution. \n",
    "\n",
    "The generative process for the player's capital evolution over a long run of time can then be viewed as defining an initial condition (starting capital), sampling a new transformation of player's capital from one of the 1.45 x 10^42 possible transformations, resolving that shoe (deterministic transformation of player capital), then as the shoe is reshuffled, sampling a new transformation from the distribution and so on, indefinitely.\n",
    "\n",
    "For each class of strategy (naive, Basic, Advantage) we now have a process for generating trajectories, or time-series for the player's capital over a possibly infinitely long run of shoes. Although we have been able to specify the process generatively in principle, at each stochastic time point, there are N possible shoes that can be drawn, where $N = 1.45 \\cdot 10^{42}, 2.47 \\cdot 10^{184},  1.56 \\cdot 10^{280}$ possible shoes that can be drawn.\n",
    "\n",
    "There a number of issues however with attempting to deduce the player's capital after an infinitely long run of time. \n",
    "\n",
    "We can do better and establish a theoretical solution to the problem and specify representative ensembles of trajectories for the three strategies. Each representative ensemble can then be conceptualised as a branching tree. Beginning with initial player capital, there will be N possible shoes that we can draw from the distribution of shoes, and for T iterations, our representative ensemble will consist of all $N^T$ possible trajectories or time series that can be traversed, depending on the sequence of shoes drawn.\n",
    "\n",
    "We have already established that there are difficulties with trying to compute one trajectory for an infinitely long period of time. We have also established a way of viewing representative ensembles together with a generative process for trajectories for each, and in an ideal World, such as having infinite computing power, we might be able to know the properties of each ensemble with absolute certainty. \n",
    "\n",
    "Provided each of the trajectories in the representative ensembles possessed particular time-series properties, we would be in a position to use the ergodic theorem and instead of computing a time average of the player's capital stock over a long period of time, use its interchangeability with the ensemble mean (which we would have in the ideal world) to make a probabilistic statement about the long-run behaviour of the player's capital stock.\n",
    "\n",
    "However, due to the very large number of possible shoes that can be drawn, and also because we want to be able to characterise the tracjectories over a long run of time, it makes this problem computationally intractable. \n",
    "\n",
    "It may be turn out to be possible to prune some of these trajectories as redundant, as if we are interested in a finite number T iterations.\n",
    "\n",
    "At this stage, we see two ways of proceeding:\n",
    "\n",
    "1) Devise a clever analytic argument using mathematical sleight of hand.\n",
    "\n",
    "2) Assess if the time-series properties on which we would like to make our argument hold.\n",
    "\n",
    "2a) If not, see if we can apply a series of transformations to do so.\n",
    "\n",
    "3) In this way, we will have established a way of making a connection between the ensemble mean and the long run behavior of player's capital stock.\n",
    "\n",
    "4) Even though we cannot compute the ensemble mean, we may be able to appeal to asymptotics and limit theorems such as the LLN and Central Limit Theorem over a sample of trajectories from each representative ensembles to garner the estimators and statistical properties of the ensemble mean.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* Player capital vs first differencing. \n",
    "* How is your work similar or different to Millman's work?\n",
    "* Equiprobability vs ergodic theory vs independence\n",
    "* What is the difficulty with trying to compute the trajectories for a long period of time?\n",
    "* Identify and track how the metaphors are working e.g. sampling from functions, random variables, transformations of player capital."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation details \n",
    "\n",
    "* Software implementation.\n",
    "* Hardware details.\n",
    "* Validation of functionality.\n",
    "\n",
    "We used Python to write a functional simulator that would be able to mimick the process of the game being played. The code has not been optimised. It could have been made faster and more efficient by using the NumPy arrays rather than Python's native list data-structure. That is because NumPy arrays are compiled, whereas Python lists are not.\n",
    "\n",
    "We simulated [INSERT] independent [INSERT] round trajectories under Basic Strategy and HI-LO Card Counting. The process took [INSERT] hour to run on an 8GB RAM, Intel Core i7 CPU @ ~ 2.2 GHz, laptop.\n",
    "\n",
    "The code is available in the following GitHub repository: [INSERT].\n",
    "\n",
    "During the process of coding the simulator, there was already a degree of validation of its functionality that occurred at the writing and debugging stage.\n",
    "\n",
    "However to have a greater degree of confidence on whether the simulator was working correctly, the simulator was setup to produce a logfile for one trajectory of 1,000 hands under a Basic Strategy and under HI-LO Card Counting. The following was assessed:\n",
    "\n",
    "* Same initial conditions (i.e. permutation of the shuffled shoe is the same) for both trajectories.\n",
    "* That both simulators are correctly detecting when there is a player blackjack.\n",
    "* That both simulators are correctly resolving the round in terms of player decision-action sequences on whether to hit, stand, double, and split.\n",
    "* That both simulators are correctly resolving the round in terms of dealer's fixed rules on hitting and standing.\n",
    "* That both simulators are correctly encoding the outcomes of the round by comparing the player and dealer hands.\n",
    "* That both simulators are correctly computing the amount won or loss in each round by the player according to the outcome of the round.\n",
    "* That both simulators are appropriately recording changes to the player's capital stock.\n",
    "\n",
    "Specific only to the HI-LO Card Counting simulator, the following was assessed:\n",
    "\n",
    "* That the simulator is correctly tracking the running count and total number of cards dealt in each round; and in particular, resetting the counts when the shoe is reshuffled.\n",
    "* That the simulator is correctly computing the true count from the running count and the total number of cards dealt.\n",
    "* That the simulator is correctly using the true count to vary bets according to the bet staircase specified.\n",
    "\n",
    "Ideally, these aspects would be formally tested using coded tests in the vein of good software engineering, design and practice. This was not conducted. Instead, the predefined sample of hands will be selected, and examined by manual inspection of the accompanying output messages.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* To permit experimental comparison of the time-series under both strategies, a fixed random seed that was the same for both simulations was set.\n",
    "* As a further check, the contents of the first shuffled shoe was output under both strategies. That the contents of the cards in both shoes were the same confirmed that both simulations were run with the same initial conditions.\n",
    "* A more involved check would mean writing code that checks whether the shuffled shoe for every shoe played in the 1,000 hand trajectory is the same. \n",
    "\n",
    "\n",
    "\n",
    "* Look up the precise explanation for why NumPy is faster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Footnotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - the architecture that the ENIAC was contained in a now declassified research report known as the \"First Draft Report of the EDVAC\" in 1945, and is still being used to today in modern digital computers, although it is now known as a \"von Neumann architecture\". \n",
    "\n",
    "2- To further illustrate the way in which the notion of expected value must be treated with caution and the issues that it can engender, consider the following. Assume that we would like to know the average number of ovaries that a person in the population has, that the ratio of males:females in the population is in equal proportion, and that everyone has either two ovaries or two testes. If we are sloppy in interpretation, we might conclude using expected values that the number of ovaries the average person has in this population is 1 via the calculation (2 x 1/2) + (0 x 1/2). However, *no-one* in this hypothetical population is really endowed with only one ovary, and there are instead equal numbers of people with no ovaries and two ovaries.\n",
    "\n",
    "3- There are some interesting parallels between the situation Thorp highlighted and some of the historical methods that previous figures have adopted when dealing with this kind of analytically or combinatoriall intractable problems. Some notable examples would be Henri Poincare's treatment of the 3 body problem by qualtitative characterisation of the profiles of orbits in phase space, and Williard Gibbs in dealing with the derivation of macroscropic observables of conservative systems, and the ergodic theorem, which brought a statistical and probabilistic approach to the seemingly intractable problem of the collisions of systems with atoms too numerous to count. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.gamblingcommission.gov.uk/for-gambling-businesses/Compliance/Sector-specific-compliance/Casinos/Casino-games.aspx\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix I - Recursive algorithm for Basic Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We synthesise the work of Micahel Shackeleford and Chongwu Ruan to bring together a set of verified, and subsequently adapted recursive formulae for calculation the Basic Strategy decision table and House Edge in an Excel spreadsheet application with a conditional formatting functionality. \n",
    "\n",
    "There are 16 recursive formulae, and the construction of the Basic Strategy table, followed by the House \"Edge\", or overall mathematical expectation to the player is computed using the following steps. This is an instance of nested recrusion. In the sense of recursive use of previous steps and recursion within each step. Assuming a unitary bet:-\n",
    "\n",
    "    * Compute probabilities of outcomes for the dealer conditioned on the possible upcards they can receive.\n",
    "    * Compute the expected value of the player electing to stand for both hard and soft hands, for all possible player hands, and for all possible dealer upcards. Hard-soft hand distinction no longer explicitly mentioned from hereon.\n",
    "    * Compute decision function for player electing to hit and to stand as a function of expected values under both actions.\n",
    "    * Compute expected values for the player electing to double down \n",
    "    * Compute decision function for player electing to hit, stand or double.\n",
    "    * Compute the expected value for player electing to surrender.\n",
    "    * Compute the expected value of the player electing to split.\n",
    "    * Compute the decision function for whether or not to split.\n",
    "    * Compute probabilities\n",
    "    * Compute expected returns\n",
    "    * Compute unconditional expected values\n",
    "    * Compute overall expectation.\n",
    "\n",
    "As this was written with the view to reproducibility, we present all the recursive formulae with exposition. This should make it possible for the reader, should they wish, to verify the validity of these calculations for themselves.\n",
    "\n",
    "$y$ - set of possible outcomes that the dealer may have.\n",
    "\n",
    "$x$ - set of possible totals that the player may have in their hand.\n",
    "\n",
    "$P_y(x)$ - conditional probability of the dealer having outcome $y$ when their hand is $x$.\n",
    "\n",
    "$P^\\text{hard}_y(x)$ - conditional probability of the dealer having the outcome $y$ when their hand is a hard $x$.\n",
    "\n",
    "$P^\\text{soft}_y(x)$ - conditional probability of the dealer having the outcome $y$ when their hand is a soft $x$\n",
    "\n",
    "$$ y \\in \\{\\text{B}, 17, 18, 19, 20, 21 \\} \\\\\n",
    "   x \\in \\{\\underbrace{2, 3, 4, 5, ..., 31}_\\textrm{hard}; \\underbrace{12, 13, 14, 15,..., 31}_\\textrm{soft}\\}$$\n",
    "\n",
    "We use the logic of the game to automatically populate the following probabilities:\n",
    "\n",
    "* $P^\\text{hard}_{B}(x) = 1$ for $x = {22,...,31}$ - the dealer's conditional probability of busting given a hard total of 22 or above, up to 31, is 1.\n",
    "\n",
    "\n",
    "* $P_y(x) = 1$ for $y=x={17, 18, 19, ... 21}$ - the dealer's conditional probability of getting an outcome between 17 and 21, given that they have that total in their hand is 1, as they must stick if they have a value of 16 or greater.\n",
    "\n",
    "\n",
    "* $P^\\text{soft}_y(x) = P^\\text{hard}_y(x)$ for $ x = {22, ..., 31}$ - the dealer's conditional [probability of getting a "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix II - Results required to formulate FTOC, statistical justification, supplementary theorems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Permutations - well shuffled decks and exchangeability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the preliminaries that set up the FTOC may seem unfamiliar. The permutation notation and exchangeability at the beginning are ways of formalising the idea of a shuffled and well-shuffled deck. As it is necessary to understand this notation as a means of stating the FTOC, we reproduce the relevant excellent sections of Ethier (2010) here.\n",
    "\n",
    "* For a deck of $N$ distinct cards, which are defined as in FTOC i.e.\n",
    "* We label these cards $1,2, 3,...,N$.\n",
    "* More specifically, we label the positions of the cards in the deck as follows:\n",
    "* With the cards face down, the top card in the deck is in position 1, the second card is in position 2, and so on.\n",
    "* In particular, when the first card is dealt, the card in position 1 is dealt first.\n",
    "\n",
    "\n",
    "* We define a *permutation* $\\pi$ of $(1, 2, 3,...,N)$ to be a *one-to-one mapping*, $\\pi : \\{1, 2, 3,...,N\\} \\mapsto \\{1, 2, 3,...,N\\}$.\n",
    "* The *symmetric group* $S_N$ is the group of all permutations of $(1, 2, 3,..., N)$, with group operation given by composition of mappings, that is, $\\pi_1 \\pi_2 := \\pi_2 \\circ \\pi_1$, where $(\\pi_2 \\circ \\pi_1)(i) := \\pi_2(\\pi_1(i))$.\n",
    "* The number of permutations iin $S_N$ is $N!$.\n",
    "\n",
    "There a a number of helpful ways of thinking about this.\n",
    "\n",
    "* $\\pi(i) = j$ means that the card in position $i$ is moves to position $j$ under the permutation $\\pi$.\n",
    "* If the cards are in natural order $(1, 2, 3,...,N)$ to begin with, then the *equivalent* statement $\\pi^{-1}(j) = i$ means that position $j$ contains card $i$ after the permutation $\\pi$ is applied.\n",
    "* A conveninent representation for a permutation $\\pi \\in S_N$ is\n",
    "\n",
    "$$(\\pi^{-1}(1), \\pi^{-1}(2), \\pi^{-1}(3), ..., \\pi^{-1}(N))$$\n",
    "\n",
    "* This gives the order of the deck after permutation $\\pi$ is applied, assuming that the deck was in natural order $(1, 2, 3,..., N)$ to begin with. Thus a shuffle is a permutation of $(1, 2, 3,...,N)$, which is typically random but need not be.\n",
    "\n",
    "We can also define notation to formalise the idea of a *well-shuffled* deck. \n",
    "\n",
    "* If $\\Pi$ denotes the *random permutation* of $(1, 2, 3,...,N)$ that describes the deck ordering, we assume $\\Pi$ to have the discrete uniform distriubtion.\n",
    "* A similar \"grammar\" holds for *random permutations* as with permutations.\n",
    "* That is, $\\Pi(i) = j$ means that the card in position $i$ is moved to position $j$ by the random permutation. If the cards are in natural order $(1, 2, 3,...,N)$ initially, then a convenient representation for a random permutation is:\n",
    "\n",
    "$$(\\Pi^{-1}(1), \\Pi^{-1}(2), \\Pi^{-1}(3), ..., \\Pi^{-1}(N))$$\n",
    "\n",
    "* This is the order of the cards in the deck after $\\Pi$ has been applied.\n",
    "* For example, card $j$ is in position 1 after the shuffle if $\\Pi^{-1}(1) = j$, or equivalently, if $\\Pi(j) = 1$, that is, if the card in position $j$ initially, namely card $j$, is moved to position 1 by the shuffle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following theorem establishes a link between a *well-shuffled deck* is a *exchangeable*. That is, if the cards are permuted in an arbitrary nonrandom way (or even in a random way under certain conditions), the deck will remain well-shuffled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theorem 11.2.1.\n",
    "\n",
    "Let $\\Pi$ be an $S_N$-valued random variable with the discrete uniform distribution.\n",
    "\n",
    "a) If $\\pi_1, \\pi_2 \\in S_N$, then $\\pi_1 \\circ \\Pi$ and $\\Pi \\circ \\pi_2$ have the discrete uniform distribution.\n",
    "\n",
    "b) If $\\Pi$ (resp. $\\Pi_2$ is an $S_N$-valued random variable independent of $\\Pi$, then $\\Pi_1 \\circ \\Pi$ (resp.,  $\\Pi \\circ \\Pi_2$) has the discrete uniform distribution.\n",
    "\n",
    "c) If $\\lambda : S_N \\mapsto S_N$ is one-to-one and nonrandom, then $\\lambda(\\Pi)$ has the discrete uniform distirbution.\n",
    "\n",
    "d) $\\Pi^{-1}$ has the discrete uniform distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proof.\n",
    "\n",
    "a) $P(\\pi_1 \\circ \\Pi = \\pi) = P(\\Pi = \\pi^{-1} \\circ \\pi) = 1/N!$ for all $\\pi \\in S_N$. The other case is similar.\n",
    "\n",
    "b) This from part (a) by conditioning on $\\Pi_1$ (resp., $\\Pi_2$).\n",
    "\n",
    "c) $P(\\lambda(\\Pi) = \\pi) = P(\\Pi = \\lambda^{-1}(\\pi)) = 1/N!$ for all $\\pi \\in S_N$.\n",
    "\n",
    "d) This is a special case of part c)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notion of exchangeability is more general. If $X_1, X_2, ..., X_N$ are jointly distributed discrete random variables, we say that they are *exchangeable* if the joint distribtuion of $X_{\\pi(1)}, X_{\\pi(2)}, X_{\\pi(3)}, ..., X_{\\pi(N)}$ coincides with that of $X_1, X_2, X_3,...,X_N$ for all permutations $\\pi \\in S_N$.\n",
    "\n",
    "For example, if $\\Pi$ is as Theorem 11.2.1, and $X_j := \\Pi{-1}(j)$ for $j = 1, 2, 3,..., N$, then $X_1, X_2, X_3,...,X_N$ are exchangeable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exchangeable random variables.\n",
    "\n",
    "An *exchangeable sequence* of random variables is a sequence $X_1, X_2, X_3,...,$ (which may be infinitely long) whose joint probability distribution does not change when the positions in th sequence in which finitely many of them appear are altered.\n",
    "\n",
    "As an example, $X_1, X_2, X_3, X_4, X_5, X_6$ and $X_3, X_6, X_1, X_5, X_2, X_4$ both have the same joint probability distribution.\n",
    "\n",
    "Definition.\n",
    "\n",
    "An *exchangeable sequence of random variables* is a finite (or infinite) sequence $X_1, X_2, X_3,...$ of random variables such that for any *finite permutation* $\\sigma$ of the the indices $1, 2, 3,...$ (the permutation acts on only finitely many indices; the rest are fixed), the *joint probability* of the *permuted sequence* $X_{\\sigma(1)}, X_{\\sigma(2)}, X_{\\sigma(3)},...,$ is the same as the joint probability distribution of the original sequence $X_1, X_2, X_3,...$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Martingales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The terminology of the FTOC as formulated by Ethier (2010) and Ethier and Levin (2005) requires some familiarity with a type of stochastic process that is often used in context of gambling and betting - martingales. Martingales have been long studied, and have been associated with gambling since their conception. Again, we list some definitions and properties from Ethier (2010) on martingales in one place/\n",
    "\n",
    "Informally, a martingale is a sequence of discrete random variables indexed by a time parameter with the proerpty that the conditional expectation of a future term given the past and present terms is the present term. In the academic literature on gambling, and in mathematics, martingales are often used as a stochastic model for a gambler's fortune in a *fair game*.\n",
    "\n",
    "* Let $\\{X_n\\}_{n \\geq 0}$ be a sequence of jointly distributed discrete random variables (or random vectors).\n",
    "* This sequence is called a *filtration*, and is our basic source of randomness.\n",
    "* Often the filtration is indexed by the positive integers rather than the non-negative ones.\n",
    "* In such cases, $X_0$ is understood to be a constant for the purpose of the definitions.\n",
    "* We say that a sequence of discrete random variables $\\{M_n\\}_{n \\geq 0}$ is a *martingale with respect to* $\\{X_n\\}_{n \\geq 0}$ if there exists a sequence $\\{f_n\\}_{n \\geq 0}$ of nonrandom functions such that:\n",
    "\n",
    "$$M_n = f_n(X_0, X_1, ..., X_n), \\quad \\mathbb{E}\\left[|M_n|\\right] < \\infty,$$\n",
    "\n",
    "and\n",
    "\n",
    "$$ \\mathbb{E}[M_{n+1} | X_0, X_1,...,X_n] = M_n$$\n",
    "\n",
    "for all $n \\geq 0$\n",
    "\n",
    "(3.2) implies that $\\mathbb{E}[M_{n+1}] = \\mathbb{E}[M_{n}]$, so the sequence of expectations $\\mathbb{E}[M_0]$, $\\mathbb{E}[M_1]$...is constant, via the law of iterated expectations.\n",
    "\n",
    "On the interpretation of a martingale as a stochastic model for the gambler's fortune in a fair game. Under this interpretation:\n",
    "\n",
    "* $X_0$ is constant\n",
    "* $X_n (n \\geq 1)$ represents the result of the $n$th coup\n",
    "* $M_0$ is the gambler's initial fortune\n",
    "* $M_n (n \\geq 1)$ represents her fortune after $n$ coups.\n",
    "* (3.1) sates that the gambler's fortune following the $n$th coup depdends solely on the first $n$ coups (there is no other source of randomness) and has finite expectation.\n",
    "* (3.2) expresses the fairness requirement - the gambler's conditional expected profit from coup $n+1$ is 0.\n",
    "\n",
    "It also necessary to define *submartingales* and *supermartingales*. These are variants in which the current observation is not equal to future conditonal expectation, but instead a lower or upper bound, respectively, on the conditional expectation. More concretely, if $\\{M_n\\}_{n \\geq 0}$ satisfies the definition of a martingale with respect to $\\{X_n\\}_{n \\geq 0}$, then in the case that:\n",
    "\n",
    "* $\\mathbb{E}[M_{n+1} | X_0, X_1,...,X_n] \\leq M_n$, then $\\{M_n\\}_{n \\geq 0}$ is a *supermartingale with respect to* $\\{X_n\\}_{n \\geq 0}$.\n",
    "\n",
    "\n",
    "* $\\mathbb{E}[M_{n+1} | X_0, X_1,...,X_n] \\geq M_n$, then $\\{M_n\\}_{n \\geq 0}$ is a *submartingale with respect to* $\\{X_n\\}_{n \\geq 0}$.\n",
    "\n",
    "The sequence of expectations $\\mathbb{E}[M_0]$, $\\mathbb{E}[M_1]$,... is nonincreasing for a supermartingale, and nondecreasing for a submartingale.\n",
    "\n",
    "Similarly, in the same way a martingale models the gambler's fortune in a fair game, a supermartingale models the gambler's fortune in a *subfair* game; whilst the submartingale models the gambler's fortune in a *superfair* game.\n",
    "\n",
    "Every martingale is simultaneously a submartingale and supermartingale.\n",
    "\n",
    "A convex function of a martingale is a submartingale, by Jensen's inequality.\n",
    "\n",
    "A concave function of a martingale is a supermartingale.\n",
    "\n",
    "* Definition of fair, subfair, and superfair games."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jensen's Inequality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Ethier (2010):\n",
    "\n",
    "Let $I \\subset \\mathbb{R}$ be an interval; and $f : I \\mapsto \\mathbb{R}$ be a convex function. Let $\\mathbf{X}$ be a discrete random vector and let $Y$ be a discrete random variable with values in $I$, jointly distributed with $X$. If each of $Y$ and $f(Y)$ has finite expectation, then:\n",
    "\n",
    "$$ f(\\mathbb{E}[Y | \\mathbf{X}]) \\leq \\mathbb{E}[f(Y) | X]$$\n",
    "\n",
    "If, in addition, $f$ is strictly convex, then equality holds in (2.34) if and only if the conditional distribution of Y given $X$ is degenerate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical justification of hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The theorem says that the choice of $c(1), c(2),..., c(N)$ that provides the best fit, in the sense of minimising the sum of squared residuals:\n",
    "\n",
    "$$\\sum_{U \\subset D : |U| = N-m}{\\left( E_U - \\frac{1}{|U|}\\sum_{i \\in U}{c(i)} \\right)^2}$$\n",
    "\n",
    "is $c(j) := \\mu - (N-1)e(j)$ for $j=1, 2,..., N$.\n",
    "\n",
    "It will be convenient to use the standard notation of linear statistical models, namely that $\\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{\\epsilon}$.\n",
    "\n",
    "We number the subsets $U \\subset D$ with $|U| = N - n$.\n",
    "\n",
    "If $U$ is the $i$th one, we let $Y_i = E_U$, $\\epsilon_i = \\varepsilon_U$, and $X_{ij} = \\mathbf{1}_U(j)$ and $\\beta_j = c(j)/|U|$ for $j=1, 2,...,N$\n",
    "\n",
    "We want to minimise over all $\\boldsymbol{\\beta}$:\n",
    "\n",
    "$$\\sum_i{\\left(Y_i - \\sum^N_{j=1}{X_{ij}\\beta_j}\\right)}X_{ik} = 0$$\n",
    "\n",
    "or:\n",
    "\n",
    "$$\\sum_i{Y_i X_{ik}} = \\left( \\sum_i{X^2_ik} \\right) \\beta_k + \\sum_{j : j \\neq k}{ \\left( \\sum_i{X_{ij}X_\n",
    "{ik}} \\right) \\beta_j}$$\n",
    "\n",
    "for $k = 1,2,...,N$. Now:\n",
    "\n",
    "$$\\sum_i{X^2_{ik}} = \\binom{N-1}{N-n-1}, \\quad \\sum_i{X_{ij} X_{ik}} = \\binom{N-2}{N-n-2}, \\quad j \\neq k$$\n",
    "\n",
    "and\n",
    "\n",
    "$$ \\mu = \\frac{\\sum_i{Y_i X_{ik}} + \\binom{N-1}{N-n}(\\mu + e(k))}{\\binom{N}{N-n}}$$\n",
    "\n",
    "The latter equation follows from the fact that if we average $E_U$ over all subsets $U \\subset D$ with $|U| = N-n$, considering separately those $U$ for which $k \\in U$ (the first term in the numerator) and those $U$ for which $k \\notin U$ (the second term in the numerator), we get $\\mu$. We also require that $N-n \\geq m$, so that the next coup can be completed. Now (11.83) implies that :\n",
    "\n",
    "$$\\begin{align}\n",
    "\\sum_i{Y_i X_{ik}} &= \\binom{N}{N-n}\\mu - \\binom{N-1}{N-n}(\\mu + e(k)) \\\\\n",
    "                   &= \\binom{N-1}{N-n-1}\\mu - \\binom{N-1}{N-n}e(k)\n",
    "\\end{align}$$\n",
    "\n",
    "which when substituted together with (11.82) back into (11.81) yields:\n",
    "\n",
    "$$\\binom{N-1}{N-n-1}\\mu - \\binom{N-1}{N-n}e(k) = \\binom{N-1}{N-n-1} \\beta_k + \\binom{N-2}{N-n-2} \\sum _{j: j \\neq k}{\\beta_j}$$\n",
    "\n",
    "Letting $\\beta := \\beta_1 + \\beta_2 + ... + \\beta_N$, we can simplify this algebraically to:\n",
    "\n",
    "$$ \\mu - \\frac{n}{N-n}e(k) = \\beta_k + \\frac{N-n-1}{N-1}(N \\beta - \\beta) = (N-n)\\beta $$\n",
    "\n",
    "and therefore that $\\beta = N \\mu/(N-n)$. Substituting back into (11.86), and solving for $\\beta_k$, we conclude that:\n",
    "\n",
    "$$\\beta_k = \\frac{\\mu - (N-1)e(k)}{N-n}$$\n",
    "\n",
    "as required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Central Limit Theorems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theorem 1.5.14.\n",
    "\n",
    "Let $S_{n, N, K}$ be hypergeometric$(n, N, K)$. Then\n",
    "\n",
    "$$\\frac{S_{n, N, K} - n(K/N)}{\\sqrt{n(K/N)(1-K/N)(N-n)(N-1)}} \\overset{D}{\\to} N(0,1)$$\n",
    "\n",
    "provided $n, N, K \\to \\infty$ in such a way that $n/N \\to \\alpha \\in (0,1)$ and $K/N \\to p \\in (0,1)$.\n",
    "\n",
    "Theorem A.2.13.\n",
    "\n",
    "For each $N \\geq 2$, let $(X_{N,1}, X_{N,2},...,X_{N,N})$ have the discrete uniform distribution over all $N!$ permutations of the $N$ (not necessarily distinct but not all equal) numbers $x_{N,1}, x_{N,2},..., x_{N,N}$, and define:\n",
    "\n",
    "$$ \\mu_N := \\mathbb{E}[X_{N,1}] = \\frac{1}{N} \\sum^N_{j=1}{x_{N,j}}$$\n",
    "\n",
    "and\n",
    "\n",
    "$$ \\sigma^2_N := \\text{Var}(X_{N,1}) = \\frac{1}{N} \\sum^N_{j=1}{(x_{N,j} - \\mu_N)^2}$$\n",
    "\n",
    "Assume that:\n",
    "\n",
    "$$ \\max_{1 \\leq j \\leq N} \\frac{\\left | x_{N,j} - \\mu_N \\right |}{\\sqrt{N \\sigma^2_N}} \\to 0 $$\n",
    "\n",
    "as $N \\to \\infty$. Then, with $S_{N,n} := X_{N,1} + X_{N,2} + ... + X_{N,n}$, we have:\n",
    "\n",
    "$$ \\frac{S_{N,n} - n \\mu_N}{\\sqrt{n \\sigma^2_N (N-n)(N-1)}} \\overset{D}{\\to} N(0,1)$$\n",
    "\n",
    "provided that $n, N \\to \\infty$ in such a way that $n/N \\to \\alpha \\in (0,1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FTOC (fixed strategy) Proof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Ethier (2010):\n",
    "\n",
    "First the martingale property is a consequence of:\n",
    "\n",
    "$$Z_n = \\mathbb{E}[Y_{N-m} | X_1, X_2, ..., X_n], \\quad n = 0, 1,..., N-m$$\n",
    "\n",
    "which holds by the virtue of the exchangeability $X_1, X_2, X_3,...,X_N$. From this follow (11.68), the submartingale property of $\\{\\varphi(Z_n)\\}_{n = 0, 1,..., N-m}$ and (11.70). Taking $\\varphi(u) := u^2$ in (11.70) and using (11.68), we deduce (11.69).\n",
    "\n",
    "Now let us assume that $\\varphi$ is strictly convex. Fix $n \\in \\{0, 1,..., N-m-1\\}$ and suppose that $\\mathbb{E}[\\varphi(Z_n)] = \\mathbb{E}[\\varphi(Z_{n+1})]$. Then:\n",
    "\n",
    "$$\\mathbb{E}[\\varphi(\\mathbb{E}[Z_{n+1} | X_1, X_2,...,X_n])] = \\mathbb{E}[\\mathbb{E}[\\varphi(Z_{n+1}) | X_1, X_2,...,X_n]]$$\n",
    "\n",
    "so by the condition of equality in the form of Jensen's inequality (Theorem 2.2.3), the conditional distribution of $Z_{n+1}$ given $X_1, X_2,..., X_n$ is degenerate. By the definition of conditional expectation, there exists a nonrandom function $h_{n+1}$ such that $Z_{n+1} = h_{n+1}(X_1, X_2,...,X_{n+1}$. \n",
    "\n",
    "Further, $h_{n+1}$ is a symmetric function of its variables. Since the condtional distribution of $h_{n+1}(X_1, X_2,...,X_{n+1})$ given $X_1, X_2,...,X_n$ is degenerate, the symmetry of $h_{n+1}$ implies that $Z_{n+1}$ is constant and hence its variance is 0. The stated conclusions follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FTOC (Variable Strategy) Proof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Ethier (2010):\n",
    "\n",
    "The submartingale property of $\\{Z_n\\}_{n=0,1,...,N-m}$ follows by noting that, for $n=0,1,...,N-m-1$,\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mathbb{E}[Z_{n+1} | X_1, X_2,...,X_n] &= \\mathbb{E}[\\mathbb{E}[f_{X_1, X_2,...,X_{n+1}}(X_{n+2}, X_{n+3},..., X_{n+m+1}) | X_1, X_2,..., X_{n+1}] | X_1, X_2,..., X_n] \\\\\n",
    "&\\geq \\mathbb{E}[\\mathbb{E}[f_{X_1, X_2,..., X_{n+1}}(X_{n+2}, X_{n+3}, ..., X_{n+m+1}) | X_1, X_2,...,X_{n+1}] | X_1, X_2, ..., X_n] \\\\\n",
    "&= \\mathbb{E}[f_{X_1, X_2,...,X_n}(X_{n+2}, X_{n+3},..., X_{n+m+1}) | X_1, X_2,...,X_n] \\\\\n",
    "&= \\mathbb{E}[f_{X_1, X_2,...,X_n}(X_{n+1}, X_{n+3},..., X_{n+m}) | X_1, X_2,...,X_n] \\\\\n",
    "&= Z_n\n",
    "\\end{align}$$\n",
    "\n",
    "where the inequality uses (11.102) and the fact that $f_{X_1, X_2,..., X_n}$ is of the form $g_{X_1, X_2,...,X_{n+1}}$, and the next-to-last equality uses the exchangeability of $X_1, X_2,..., X_N$. From this follow (11.105), the submartingale property of $\\{\\varphi(Z_n)\\}_{n=0,1,...,N-m}$ and (11.106).\n",
    "\n",
    "Assume next that $\\varphi$ is strictly convex and increasing. Fix $n \\in \\{0, 1,..., N-m-1\\}$ and suppose that $\\mathbb{E}[\\varphi(Z_n)] = \\mathbb{E}[\\varphi(Z_{n+1})]$. Then by (11.107) and the conditional form of Jensen's inequality (Theorem 2.2.3),\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mathbb{E}[\\varphi(Z_n)] &\\leq \\mathbb{E}[\\varphi(\\mathbb{E}[Z_{n+1} | X_1, X_2,...,X_n])] \\\\\n",
    "                         &\\leq \\mathbb{E}[\\mathbb{E}[\\varphi(Z_{n+1}) | X_1, X_2,..., X_n]] = \\mathbb{E}[\\varphi(Z_{n+1})]\n",
    "\\end{align}$$,\n",
    "\n",
    "hence the inequalities are equalities. The argument in the proof of Theorem 11.3.4. applies to the second equality in (11.108), resulting in $\\text{Var}(Z_{n+1}) = 0$. Moreover the first equality in (11.108), together with the increasing property of $\\varphi$ and (11.107), tells us that $\\text{Var}(Z_n) = 0$.\n",
    "\n",
    "* Convert notation to $f*$ or backwards "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project questions that need to be resolved/acknowledged (steering) - list them here no matter how trivial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
